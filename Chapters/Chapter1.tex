% Chapter 1
\newcommand{\formatprogramnames}[1]{\texttt{#1}}
\newcommand{\ce}{\formatprogramnames{chloroExtractor}}
\newcommand{\oa}{\formatprogramnames{ORG.Asm}}
\newcommand{\fp}{\formatprogramnames{Fast-Plast}}
\newcommand{\ioga}{\formatprogramnames{IOGA}}
\newcommand{\np}{\formatprogramnames{NOVOPlasty}}
\newcommand{\go}{\formatprogramnames{GetOrganelle}}
\newcommand{\cassp}{\formatprogramnames{Chloroplast assembly protocol}}



\chapter{Benchmarking of Chloroplast Genome Assembly tools } % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1}
This chapter orientates on \cite{freudenthal2019landscape} only the chapters from the publication which the author majorly contributed to are included. 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Introduction}
\subsection{Motivation}

Circular DNA of a size between 120 kBP to 160 kBP \cite{palmer_1985}.  First chloroplast sequenced as early as
1986 \textit{Marchantia polymorpha} and \textit{Nico} \cite{ohyama_chloroplast_1986};
\cite{shinozaki_complete_1986}.  Review genome structure \cite{green_chloroplast_2011};
\cite{wicke_evolution_2011}.  Chloroplast genomes widely used in evolutionary studies
\cite{martin_evolutionary_2002}; \cite{xiao-ming_inferring_2017}.  Chloroplast genomes are small through
endosymbiotic gene transfer \cite{martin_evolutionary_2002}; \cite{deiner_environmental_2017}. Up to 14 \% of
the the core genome of \textit{Arabidopsis thaliana} is made up of genes previously from the chloroplast
(fancy citation), while 100-120 genes remain on the chloroplast \cite{wicke_evolution_2011}.  However
chloroplast between plant species show large variety e.g. parasitic plants.  Chloroplast genomes are much
smaller than core genomes e.g \textit{A. thaliana} ca. 125 MBP. Highly conserved high gene content, therefore
changes are more likely to be functional.  Single chloroplast contain up to hundreds of copies of its genome
\cite{kumar_2014}; \cite{bendich_1987}, and photosynthetic activate cells contain multiple chloroplasts,
therefore the copy number of chloroplast genomes is much higher than number of core genomes per cell.
Structurally chloroplast genomes consist of two inverted repeats (IR) - $IR_A$ and $IR_B$ - ranging from 10
kbp to 76 kB the divide the chloroplast genome into two distinct regions the large single copy (LSC) and the
small single copy (SSC) as shown in \ref{fig:cpast_genome} \cite{palmer_1985}. Taking into account that the
majority of assembly tools has been designed to assemble linear core genomes, the structure of chloroplast
genomes is a major obstacle when wanting to assemble those genomes with modern short read technologies,
especially solving and aligning the IR \cite{Wang2018}. 

\begin{figure}[H]
\centering
\includegraphics[height=.55\textheight, width=.95\textwidth]{Figures/cpast}
\decoRule
\caption[Structure of a chloroplast genome]{Structure of the chloroplast genome of \textit{A. thaliana} with SSC-Region and LSC-Region. Length of the genome and its parts in kbp. Graphic from \cite{olejniczak2016chloroplasts}}
\label{fig:cpast_genome}
\end{figure}

Chloroplast genomes present biologist with many obstacles of which heteroplasmy stands out and immensely
complicated genome assemblies and downstream analyses \cite{corriveau_1988}; \cite{Chat2002}.  Heteroplasmy
describes the phenomenon of co-existence of multiple versions of the chloroplast genomes in a single organism
and single cells of that respective organism. The underlying evolutionary mechanisms behind heteroplasmy are no
fully elucidated and eventually existing fitness advantages fueling heteroplasmy cannot be explained
satisfactory by evolutionary methods \cite{Scar2016}.
There is a variety of databases containing short read data for species without an chloroplast genome available. For example NCBI's the short read archive (SRA) \cite{SRA2010}. Because most plant DNA extraction protocols use green leaf tissue as basis, they usually contain a large amount of plastid DNA. Having  larger number of assembled and annotated chloroplast genomes publicly available would be beneficial for evolutionary studies and could be a useful addition to bar-coding and super-barcoding \cite{coissac_barcodes_2016} and other biotechnological applications \cite{daniell_chloroplast_2016}. To achieve this there is a variety of tools available. The study presented in this chapter, assesses the availability, usability and overall performance of 7 of those tools and ultimately makes use of the newly gained insights to attempt \textit{de novo} assemble more than 100 chloroplast




\subsection{Extraction of chloroplast reads from whole genome data and general assembly workflow}
There is a variety of strategies to assemble chloroplast genomes from raw sequencing data \cite{twyford_strategies_2017}. In general the process involves three steps: (i) extraction of plastid reads from the WGS data, (ii) assembly of the plastid genome, (iii) solving the circular structure of the chromosome with the IRs. There are two distinct ways to tackle step (i): The first one is to map all the reads to a reference chloroplast \cite{Vinga2012}, which works reasonably well if there is one available for the same, or at least a closely related species. The second is to make use of the much larger coverage of chloroplast DNA compared to core DNA, with a k-mer analysis \cite{Chan2013}, this is for example done by \ce \cite{j_ankenbrand_chloroextractor:_2018}. The third way to accomplish this is to combine as done by \np  \cite{dierckxsens_novoplasty:_2017}.
Figure \ref{fig:cpast_workflow} shows the general workflow of chloroplast assembly too. 


\begin{figure}[H]
\centering
\includegraphics[height=.65\textheight, width=.95\textwidth]{Figures/CE_workflow}
\decoRule
\caption[Chloroplast genome assembly workflow]{Standard workflow of chloroplast genome assembly. Graphic from \cite{j_ankenbrand_chloroextractor:_2018} }
\label{fig:cpast_workflow}
\end{figure}


\subsubsection{Purpose and scope of benchmarking the landscape of chloroplast assembly tools}

The purpose of this study is to provide insights into the landscape of chloroplast assembly tools, to recommend best practices for organelle genome assemblies and to provide \textit{de novo} assemblies for many species and family's without a reference chloroplast available so far.
To be included into this study the software including the source code must be publicly available and published under the terms of a liberal free open source software e.g. GPL or MIT-license. The study was also limited to paired-end Illumina data sets as their sole input source, because they are abundantly available for this benchmark.The seven tools that me the requirements and were therefore included in this study were: \ce, \oa, \fp, \ioga, \np, \go and \cassp. As later thoroughly described in section \ref{results:ca}, there are huge differences between those tools and some will not be recommend to be used in scientific applications, while others outstand for most but not all cases.


%----------------------------------------------------------------------------------------
\section{Material and Methods}
\subsection{Methods}
\subsubsection{Data and code availability}
All the source code and data used in the scope of this study is publicly available under the terms of the MIT-License. The source code has been published on github \cite{github-benchmark-repo} and archived on zenodo \cite{zenodorepo} . The docker images are available on dockerhub \cite{dockerhub-benchmark}

\subsubsection{Tools}
There were certain requirements to be met to be included into the study as aforementioned. The only technical
requirements was, being able to assemble chloroplast genomes from paired-end Illumina reads. The other
requirements were due to reproducibility. (i) The software must be open-source and available under the terms
of a liberal software license. In the authors opinion obscuring reproducibility under paywalls cannot be
considered good scientific practice. (ii) It must be a command line tool, GUI-only tools are not suited for
highly repetitive automated analyses.  In total there were 7 tools that met those requirements: (i)
\hspace{0.5ex} \ce \hspace{0.5ex} \cite{j_ankenbrand_chloroextractor:_2018}; (ii) \hspace{0.5ex} \cassp
\hspace{0.5ex} \cite{sancho_comparative_2018}; (iii)\hspace{0.5ex} \go \hspace{0.5ex}
\cite{jin_getorganelle:_2018}; (iv) \hspace{0.5ex} \oa \hspace{0.5ex} \cite{coissac_barcodes_2016}; (v)
\hspace{0.5ex} \ioga \hspace{0.5ex} \cite{bakker_herbarium_2016}; (vi) \hspace{0.5ex} \fp \hspace{0.5ex}
\cite{mckain__fast-plast_2017}; (vii) \hspace{0.5ex} \np \hspace{0.5ex} \cite{dierckxsens_novoplasty:_2017}.
There are other tools available, that did not meet the requirements.

\subsubsection{Standardization and reproducibility}

The main goal of the study was to provided deep insights into the landscape of chloroplast assembly tools. To
accomplish that we tried to use the highest standards in bioinformatics when it comes to standardization and
reproducibility. Along the study we also wanted to publish easy and ready-to-use versions of all the involved
programs, working with standardized input. To accomplish that we decided to make us of containerization in
form of docker containers \cite{merkel2014docker} to work with the containers in a closed HPC environments we
decided a related software - singularity \cite{kurtzer2017singularity}. Therefore users do not have anything
else to do than provide two files one for the forward reads (\texttt{forward.fq}) and one for the reverse
reads (\texttt{reverse.fq}). Both files are required to be in FASTQ format. If docker or singularity are
installed no further setup is requirement, because all dependencies and packages are installed and run from
the containers on any given environment. Besides the individual output files, recording the process of the
respective program, all programs write the assembly products in to files called \texttt{output.fa} in FASTA
format.  For the quantitative and consistency measurements the singularity containers were run on the Julia
HPC-Cluster of the University of W\"{u}rzburg using the SLURM workload manager \cite{Jette02slurm}.


\subsection{Data}
Three different data sets were used for this study. (i) Simulated data from \textit{A. thaliana}
chloroplasts. (ii) real data with known reference chloroplast to rate the success of the assemblies. (iii)
Novel data sets from NCBI's SRA without a know reference chloroplast to apply the gained knowledge for the
\textit{de novo} assembly of more than 100 chloroplasts.

\subsubsection{Simulated}

For first steps in any benchmarking process it is always useful to start with simulated data, where the investigators have full control over all the parameters involved. In the case of the present study the data's input parameters thought to be influential on the outcome where: The read length, the ratio between chloroplast and core genome reads. The simulations were based on data from the TAIR10 genome \cite{tair10} and performed using \texttt{seqkit} \cite{seqkit}. Ratios simulated were: 0:1, 1:10, 1:1000 and 1:1000, with read length of 150 and 250 bp. The simulated data consisted either of 2 million read pairs or the full data available. The simulation process is documented and the code and the data is available on github and zenodo \cite{zenododataset}

\subsubsection{Real data set}\label{sec:cp_real}

Real data was selected from the SRA database table \ref{tab:sra_real} lists the search terms that had to be met according to the aforementioned search terms.


\begin{table}[H]
\caption{Data selection criteria for real data sets from SRA}
\label{tab:sra_real}
\centering
\begin{tabular}{ccl}
 \hline
  choice & option & explanation \\
 \hline
  green plants & Organism & include only photosynthetic plants e.g. no algae  \\
  wgs & Strategy & only data from wgs projects included \\
  Illumina & Platform & include only paired-en Illumina reads \\
  biomol DNA & Properties & include only biomol. DNA samples (e.g. no RNA) \\
  paired & Layout & exclude single-end reads  \\
  random & Selection & \\
  public & Access & Only publicly available data included \\
  \hline                                         
\end{tabular}
\end{table}

In total this resulted in 369 data sets representing a broad variety of the plant kingdom with many different families and genera included. 

\subsubsection{Novel data sets}

To assess the performance on assemblies without a published chloroplast on \texttt{CpBase} \cite{cpbase} 105
data sets were selected from SRA, it was emphasized that such data sets were selected, with the next relatives
with a reference chloroplast as distantly related as possible in taxonomic terms according to NCBI
\cite{ncbitaxonomy}


\subsection{Evaluation}
\subsubsection{Quantitative}

Each assembly from each assembler was compared to their respective reference genome by alignment using
minimap2 \cite{li2018minimap2} and based on those alignments scores were calculated following equation
\ref{eqn:score_ass} from 0 to 100 with 100 being a perfect score. Four different metrics contributed equally
to the final score. (i) The coverage of the assembled genome compared to the reference genome $cov_{ref}$ as
an estimate for the completeness. (ii) The vice versa case $cov_{qry}$ as a measure for the correctness of the
assembly. (iii) The success of resolving the IR correct, estimated from the size difference from the reference
and the newly assembled genome is:
$min\left\{ \frac{cov_{qry}}{cov_{ref}}, \frac{cov_{ref}}{cov_{qry}}\right\}$.  (iv) The number of total
contigs were weighted as $\frac{1}{n_{contigs}}$ giving a chloroplast with 1 contig the optimal score.

\begin{equation}
  score = \frac{1}{4} \cdot \left( cov_{ref} +  cov_{qry} + min\left\{ \frac{cov_{qry}}{cov_{ref}}, \frac{cov_{ref}}{cov_{qry}}\right\} + \frac{1}{n_{contigs} }\right) \cdot 100
  \label{eqn:score_ass}
\end{equation}

While it is difficulty to assess the success or failure of assemblies on a continuous scale, equation
\ref{eqn:score_ass} allows for objective and unbiased measurements. SNPs or other small variants do not
influence the outcome of the score, because it much more likely that there are due to in-species variation of
the plastid's genome and not caused be the assembly, and even if the latter is true it would be difficult to
evaluate that.
  
  
\subsubsection{Consistency}

In any given bioinformatical application consistency is a desired trait. All software (exceptions excluded) should given repeatedly the same input provide the same output. The same obviously or even more so holds true for assembly tools. To evaluate the reproducibility of the the 7 tools. All the 369 real data sets described in section \ref{sec:cp_real} has been used twice for assembly with each assembler and scored twice with equation \ref{eqn:score_ass}. The correlation between the first and the second scores and runs was used the measure for the robustness of a program.

\section{Results} \label{results:ca}
\subsection{Quantitative}
\subsubsection{Simulated data}

The simulated data was assembled and scored with all the tools as described above. Figure \ref{fig:sim_tiles}
shows as a tile plot the results for all data sets and assemblers. While at first sight there is no clear
correlation with the input data sets. It is obvious that there are grave differences between the
assemblers. Two programs namely \cassp \hspace{0.5ex} and \ioga \hspace{0.5ex}failed to correctly assemble a single chloroplast genome. \ioga
even fails to provide output at all for the majority of the data sets. While those two stand out as a negative
example \fp and \go stand out as a positive example perfectly or nearly perfectly assembling all the data
sets, with \go surpassing the performance of \fp. In the middle of the filed are \ce, \ioga and \oa.


\begin{figure}[H]
\centering
\includegraphics[height=.55\textheight, width=.99\textwidth]{Figures/sim_tiles}
\decoRule
\caption[Score of assemblies of simulated data sets]{Results of assemblies executed with simulated data sets.}
\label{fig:sim_tiles}
\end{figure}

While there is a significant difference between the assemblers the same is not necessarily true in general for
the other varying parameters. While \fp deals with the shorter reads of 150 bp much better than with the longer reads of 250 bp. The outcome of the other assemblies does not seem to be influenced by that. There is no difference between the full and the subsampled data sets. And while all assemblers appear to be more challenge by low chloroplast to core genome ratios of 1:10 larger rations do not affect the quality of the result as expected. 
Table \ref{tab:score_simulated} shows all the individual results for all data sets and assemblers. For the fields with no entry the respective assembler failed to provide an output.


\begin{table}[ht]
\caption{Scores of assemblies of simulated data}
\label{tab:scores_simulated}
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{rlrrrrrrr}
 \hline
 & data set & CAP & CE & Fast-Plast & GetOrganelle & IOGA & NOVOPlasty & org.ASM \\ 
 \hline
 1 & sim\_150bp.0-1 & 79.10 & 100.00 & 99.48 & 100.00 & & 91.52 & 100.00 \\ 
 2 & sim\_150bp.0-1.2M & 79.10 & 100.00 & 99.72 & 100.00 & 79.10 & 91.52 & 91.50 \\ 
 3 & sim\_150bp.1-10 & & 56.44 & 100.00 & 76.98 & & 91.52 & 78.00 \\ 
 4 & sim\_150bp.1-10.2M & & & 99.97 & 100.00 & & 91.52 & 82.72 \\ 
 5 & sim\_150bp.1-100 & 75.72 & 100.00 & 99.48 & 100.00 & 66.09 & 91.52 & 91.50 \\ 
 6 & sim\_150bp.1-100.2M & & 100.00 & 99.47 & 100.00 & & 100.00 & 100.00 \\ 
 7 & sim\_150bp.1-1000 & 79.10 & & 99.72 & 100.00 & & 91.52 & 100.00 \\ 
 8 & sim\_150bp.1-1000.2M & 79.10 & 100.00 & 99.72 & 100.00 & & 91.52 & 100.00 \\ 
 9 & sim\_250bp.0-1 & 79.10 & 100.00 & 93.82 & 100.00 & & 91.52 & 91.50 \\ 
 10 & sim\_250bp.0-1.2M & 79.10 & 100.00 & 93.83 & 100.00 & & 91.52 & 91.50 \\ 
 11 & sim\_250bp.1-10 & & 54.98 & 68.45 & 78.89 & 52.71 & 91.52 & 40.20 \\ 
 12 & sim\_250bp.1-10.2M & & & 93.00 & 100.00 & 52.67 & 87.40 & 40.20 \\ 
 13 & sim\_250bp.1-100 & 72.81 & 100.00 & 93.82 & 100.00 & & 87.40 & 100.00 \\ 
 14 & sim\_250bp.1-100.2M & & 100.00 & 93.83 & 100.00 & & 87.40 & 100.00 \\ 
 15 & sim\_250bp.1-1000 & 79.10 & 21.30 & 93.83 & 100.00 & 76.96 & 91.52 & 91.50 \\ 
 16 & sim\_250bp.1-1000.2M & 79.10 & 100.00 & 93.83 & 100.00 & 67.55 & 87.40 & 100.00 \\
 \hline
\end{tabular}}
\end{table}




\subsubsection{Real data sets}
\begin{table}[H]
\caption{\textbf{Mean scores of chloroplast genome assemblers}}
\label{tab:scores_real}
\centering
\begin{tabular}{rlrrrr}
 \hline
 & assembler & Median & IQR & N\_perfect & N\_tot \\ 
 \hline
 1 & CAP & 45.25 & 50.19 &  0 & 369 \\ 
 2 & CE & 56.55 & 71.50 & 14 & 369 \\ 
 3 & Fast-Plast & 92.80 & 23.59 & 113 & 369 \\ 
 4 & GetOrganelle & 99.83 & 20.94 & 210 & 360 \\ 
 5 & IOGA & 71.10 & 11.21 & 0 & 338 \\ 
 6 & NOVOPlasty & 75.95 & 48.69 & 58 & 369 \\ 
 7 & org.ASM & 67.35 & 91.69 & 46 & 348 \\ 
  \hline
\end{tabular}
\end{table}





\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/swarm}
\decoRule
\caption[Scores of assemblies from real data sets]{Box and swarm plots depict the results from the scoring shown in \ref{eqn:score_ass}}
\label{fig:swarm}
\end{figure}




\subsubsection{Consistency}

\subsubsection{Real data sets}
\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/repro}
\decoRule
\caption[Comparison between two runs with the same assembler for consistency testing ]{Swarm plots depict the results from the scoring shown in \ref{eqn:score_ass} for two independent runs for each assembler on each of the data sets}
\label{fig:consisplot}
\end{figure}


\subsubsection{Novel}


\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/upset_novel}
\decoRule
\caption[Upset plot comparing the success rates for novel data sets]{nls}
\label{fig:upset_novel}
\end{figure}

\section{Discussion}

\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/upset}
\decoRule
\caption[Upset plot comparing the success rates of of all assemblers]{Upset plot showing the intersections of success rates between assemblers. A successful assembly was defined with a score > 99 according to equation \ref{eqn:score_ass}}
\label{fig:upset}
\end{figure}


