% Chapter 1
\newcommand{\formatprogramnames}[1]{\texttt{#1}}
\newcommand{\ce}{\formatprogramnames{chloroExtractor}}
\newcommand{\oa}{\formatprogramnames{ORG.Asm}}
\newcommand{\fp}{\formatprogramnames{Fast-Plast}}
\newcommand{\ioga}{\formatprogramnames{IOGA}}
\newcommand{\np}{\formatprogramnames{NOVOPlasty}}
\newcommand{\go}{\formatprogramnames{GetOrganelle}}
\newcommand{\cassp}{\formatprogramnames{Chloroplast assembly protocol}}



\chapter{Benchmarking of Chloroplast Genome Assembly tools } % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1}
This chapter is orientated on \cite{freudenthal2019landscape}. Only the chapters from the publication which the author majorly contributed to are included. If not cited otherwise the plots even though they were published along the aforementioned paper were designed and generated by the author of this thesis.

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Introduction} \label{intro:cp}
\subsection{Motivation}

Certain organelles like mitochondria and chloroplasts contain their own genetic information from which they
are able to synthesize certain proteins independent of the core genome. Evolutionary this developed during
endosymbiosis, a process which underlying theory seeks to explain how eukaryotic cells formed from prokaryotes
\cite{mereschkowsky1905uber}; \cite{kutschera2005endosymbiosis}. This widely acknowledged hypothesis explains
how in the early evolution of eukaryotes, other cells were incorporated in those cells from which today's
known organelles descent. In the case of a chloroplast this was most likely a photosynthetic bacteria or
similar organism \cite{archibald2015endosymbiosis}. This process left its traces in the structure of
chloroplast genomes until today, which resemble more that of a prokaryotic genome than that of its eukaryotic
host cells. A typical chloroplast genome consists of circular DNA with a size between 120 kBP to 160 kBP
\cite{palmer_1985}, while plant core genomes are linear, organized on chromosomes and larger by multiples of
hundreds to to tens of thousands. \newline The first chloroplasts have been sequenced as early as 1986 and
were isolated from \textit{Marchantia polymorpha} and \textit{Nicotiana tabacum}
\cite{ohyama_chloroplast_1986}; \cite{shinozaki_complete_1986}. Complete reviews on the structure of
chloroplast genomes were authored by \cite{green_chloroplast_2011} and
\cite{wicke_evolution_2011}. Chloroplast genomics is widely applied in evolutionary studies aiding in
elucidating the processes involved in endosymbiosis and the development of photosynthetic plants
\cite{martin_evolutionary_2002}; \cite{xiao-ming_inferring_2017}.  Over the course of natural adaptation the
genome has been reduced in size through endosymbiotic gene transfer, a form of horizontal gene transfer, where
fractions plastid genomes are incorporated in the core DNA \cite{martin_evolutionary_2002};
\cite{deiner_environmental_2017} . This mechanism of evolution is still ongoing an can be observed \textit{in
  vitro} and was proven experimentally \cite{bock2017witnessing}; \cite{fuentes2014horizontal};
\cite{stegemann2009exchange}. \newline In the case of \textit{Arabidopsis thaliana} this resulted in 14 \% of
the core genome's genes previously being located on the chloroplast (fancy citation), while 100-120 genes
remain on the chloroplast itself \cite{wicke_evolution_2011}, which by far would not suffice to function
independently. Organelle genomes being much smaller and highly conserved with a large gene content leads to
polymorphisms being more likely to cause functional changes in the metabolism. Another difference between
organelle and core genomes is, that single chloroplast contain up to hundreds of copies of its own genome
\cite{kumar_2014}; \cite{bendich_1987} and photosynthetic active cells again contain multiple chloroplasts,
therefore the copy number of the chloroplast genomes is much higher than the number of core genomes per cell
which in most cases is 1. \newline Structurally chloroplast genomes are made up of 4 distinct regions: two
inverted repeats (IR) - $IR_A$ and $IR_B$ - ranging from 10 kbp to 76 kbp in size. They divide the genome into
two areas: the large single copy (LSC) and the small single copy (SSC) as shown in \ref{fig:cpast_genome}
\cite{palmer_1985}. Taking into account that the majority of assembly tools has been designed to assemble
linear core genomes, the structure of chloroplast genomes is a major obstacle for the assembly pipelines
functioning with modern short read technologies, especially solving and aligning the IR provides difficulties
\cite{Wang2018}.

\begin{figure}[H]
\centering
\includegraphics[height=.55\textheight, width=.95\textwidth]{Figures/cpast}
\decoRule
\caption[Structure of a chloroplast genome]{Structure of the chloroplast genome of \textit{A. thaliana} with SSC-Region and LSC-Region. Length of the genome and its parts in kbp. Graphic from \cite{olejniczak2016chloroplasts}}
\label{fig:cpast_genome}
\end{figure}

Another major issue is heteroplasmy. It describes the phenomenon of co-existence of multiple versions of the
chloroplast's genome in a single organism and single cells of that respective organism, thus complicating
genome assemblies and ongoing from there the downstream analyses \cite{corriveau_1988}; \cite{Chat2002}. The
underlying evolutionary mechanisms behind heteroplasmy are not fully elucidated and eventually existing
fitness advantages fueling heteroplasmy cannot be explained satisfactory by standard evolutionary methods
\cite{Scar2016}. \newline Derived from a multitude of plant genome projects, there is a large variety of
databases containing short read data for species without assembled organelle genomes available; e.g. NCBI's
sequence read archive (SRA) \cite{SRA2010}. Because most plant DNA extraction protocols, applied for procuring
raw input for sequencing, use green leaf tissue as their basis, they also contain a large amount of plastid
DNA, providing a valuable basis for organelle genome assemblies pipelines assess in the course of this
chapter.\newline Having larger numbers of assembled and annotated chloroplast genomes publicly available would
be beneficial for evolutionary studies and is a useful addition to bar-coding and super-barcoding
\cite{coissac_barcodes_2016} aside from other biotechnological applications
\cite{daniell_chloroplast_2016}. To obtain this there is a variety of tools available. The study presented in
this chapter assesses the availability, usability and overall performance of 7 of those assembly pipelines and
ultimately makes use of the newly gained insights to attempt \textit{de novo} to assemble more than 100
chloroplasts.

\subsection{Extraction of chloroplast reads from whole genome data and general assembly workflow}
There is large array of strategies to assemble chloroplast genomes from raw sequencing data
\cite{twyford_strategies_2017}. In general the process involves three steps: (i) extraction of plastid reads
from the WGS data, (ii) assembly of the plastid genome, (iii) solving the circular structure of the chromosome
with the IRs. There are two distinct ways to tackle step (i). The first one is to map all the reads to a
reference chloroplast \cite{Vinga2012}, which works reasonably well if there is one available for the same, or
at least a closely related species. The second is to make use of the much larger coverage of chloroplast DNA
compared to core DNA, with a k-mer analysis \cite{Chan2013}, this is for example done by \ce $\;$
\cite{j_ankenbrand_chloroextractor:_2018}.  The third way to accomplish this is to combine both approaches as
done by \np $\;$ \cite{dierckxsens_novoplasty:_2017}.  Figure \ref{fig:cpast_workflow} shows the general
workflow of chloroplast assembly tools.

\begin{figure}[H]
\centering
\includegraphics[height=.65\textheight, width=.95\textwidth]{Figures/CE_workflow}
\decoRule
\caption[Chloroplast genome assembly workflow]{Standard workflow of chloroplast genome assembly. Graphic from \cite{j_ankenbrand_chloroextractor:_2018} }
\label{fig:cpast_workflow}
\end{figure}


\subsubsection{Purpose and scope of benchmarking the landscape of chloroplast assembly tools}

The purpose of this study is to provide insights into the landscape of chloroplast assembly tools, to
recommend best practices for organelle genome assemblies and to contribute \textit{de novo} assemblies for
many species and family's without a reference chloroplast available so far to the scientific
community. \newline To be included into this study the software, including the source code, must be publicly
available and published under the terms of a liberal, free open source software license e.g. GPL or
MIT-license. The study was further restricted to paired-end Illumina data sets as their sole input source, because
they were abundantly available for this benchmark. The seven tools that me the requirements and were therefore
encompassed in this study were: \ce, \oa, \fp, \ioga, \np, \go and \cassp. As later thoroughly described in
section \ref{results:ca}, there are huge differences between those tools and some will not be recommend to be
used in scientific applications, while others outstand performance wise for most but not all cases.


%----------------------------------------------------------------------------------------
\section{Material and Methods}
\subsection{Methods}
\subsubsection{Data and code availability}
All the source code and data used is publicly available under the terms of the MIT-License. The source code
has been published on github \cite{github-benchmark-repo} and archived on zenodo \cite{zenodorepo} . The
docker images are available on dockerhub \cite{dockerhub-benchmark}.

\subsubsection{Tools}
As aforementioned there were certain requirements to be met to be included into the study . The only technical
requirements was, being able to assemble chloroplast genomes from paired-end Illumina reads. The other
requirements were dictated by reproducibility. (i) The software must be open-source and available under the
terms of a liberal software license. In the authors opinion obscuring the ability to reproduce results behind
paywalls cannot be considered good scientific practice. (ii) It must be a command line tool since GUI-only
tools are not suited for highly repetitive, automated analyses.  In total there were 7 tools that met those
conditions: (i) \hspace{0.5ex} \ce \hspace{0.5ex} \cite{j_ankenbrand_chloroextractor:_2018}; (ii)
\hspace{0.5ex} \cassp \hspace{0.5ex} \cite{sancho_comparative_2018}; (iii)\hspace{0.5ex} \go \hspace{0.5ex}
\cite{jin_getorganelle:_2018}; (iv) \hspace{0.5ex} \oa \hspace{0.5ex} \cite{coissac_barcodes_2016}; (v)
\hspace{0.5ex} \ioga \hspace{0.5ex} \cite{bakker_herbarium_2016}; (vi) \hspace{0.5ex} \fp \hspace{0.5ex}
\cite{mckain__fast-plast_2017}; (vii) \hspace{0.5ex} \np \hspace{0.5ex} \cite{dierckxsens_novoplasty:_2017}.
There are other tools available, capable of assembling circular genomes that did not meet those requirements.

\subsubsection{Standardization and reproducibility}

The main goal of the study was to provided deep insights into the landscape of chloroplast assembly tools. To
accomplish that we tried to use the highest standards in bioinformatics in terms of standardization and
reproducibility. Along with the study it was aimed to publish easy and ready-to-use versions of all the
involved programs, working with standardized input. To accomplish this docker containers
\cite{merkel2014docker} were implemented.  To work with the containers in a closed HPC environment they were
transformed into related singularity containers \cite{kurtzer2017singularity}. Therefore novel users simply
need to provide two files one for the forward reads (\texttt{forward.fq}) and one for the reverse reads
(\texttt{reverse.fq}) and run the containers without and need for further configuration or installation,
besides docker or singularity itself.  Both files are required to be in FASTQ format.  Besides the individual
output files, recording the process of the respective program, all programs write the assembly products into
files called \texttt{output.fa} in FASTA format.  For the quantitative and consistency measurements the
singularity containers were run on the Julia HPC-Cluster of the University of W\"{u}rzburg using the SLURM
workload manager \cite{Jette02slurm}.  All runs for all assemblies were set with a time limit of 48h. This was
necessary because some assemblers e.g. \ioga, if not finishing after at least 12 hours showed the tendency not
to finish after weeks of running.

\subsection{Data}
Three different data sets were used for this study. (i) Simulated data from \textit{A. thaliana}
chloroplasts. (ii) real data with known reference chloroplast to rate the success of the assemblies. (iii)
Novel data sets from NCBI's SRA without a know reference chloroplast to apply the gained knowledge for the
\textit{de novo} assembly of more than 100 chloroplasts.

\subsubsection{Simulated}

As a first steps in any benchmarking process it is always useful to start with simulated data, allowing
investigators to have full control over all the parameters involved. In the present case the data's input
parameters thought to be influential on the outcome where: The read length, the ratio between chloroplast and
core genome reads and the total size of the data set. The data simulations were based on real data from the
TAIR10 genome of \textit{A. thaliana} \cite{tair10} and spawned using \texttt{seqkit} \cite{seqkit}. Core to
chloroplast ratios simulated were: 0:1, 1:10, 1:1000 and 1:1000, with read length of 150 and 250 bp. The
artificial data consisted either of 2 million read pairs or the full data available. The simulation
process was documented and the code and the data is available on github and zenodo \cite{zenododataset}.

\subsubsection{Real data set}\label{sec:cp_real}

Real data was selected from the SRA database. Table \ref{tab:sra_real} lists the search terms that had to be
met for a plant to be included in the study from the SRA.

\onehalfspacing
\begin{table}[H]
\caption{Data selection criteria for real data sets from SRA}
\label{tab:sra_real}
\centering
\begin{tabular}{lll}
  \hline
  Choice & Option & Explanation \\
  \hline
   Organism   & green plants &  include only photosynthetic plants e.g. no algae  \\
   Strategy   & wgs          & only data from wgs projects included \\
   Platform   & Illumina     & include only paired-en Illumina reads \\
   Properties & biomol DNA   & include only biomol. DNA samples (e.g. no RNA) \\
   Layout     & paired       & exclude single-end reads  \\
   Selection  & random       & \\
   Access     & public       & Only publicly available data included \\
  \hline                                         
\end{tabular}
\end{table}
\doublespacing
\noindent
In total this resulted in 369 data sets representing a broad variety of the plant kingdom with many different
families and genera included.

\subsubsection{Novel data sets}

To assess the performance of assemblies without a published chloroplast on \texttt{CpBase} \cite{cpbase} 105
data sets were selected from SRA. It was emphasized that the chosen read libraries were as distant as possible
related to the next relatives with a reference chloroplast, related as possible in taxonomic terms according
to NCBI \cite{ncbitaxonomy}. This was achieved by a phlyogenetic analysis of the accessible data sets on SRA
by Frank F\"orster \cite{freudenthal2019landscape}.

\subsection{Evaluation}
\subsubsection{Quantitative}

Each assembly from each assembler was compared to their respective reference genome by alignment using
minimap2 \cite{li2018minimap2} and based on those alignments scores were calculated following equation
\ref{eqn:score_ass} from 0 to 100 with 100 being a perfect score. Four different metrics contributed equally
to the final score. (i) The coverage of the assembled genome compared to the reference genome $cov_{ref}$ as
an estimate for the completeness. (ii) The vice versa case $cov_{qry}$ as a measure for the correctness of the
assembly. (iii) The success of resolving the IR correct, estimated from the size difference from the reference
and the newly assembled genome as:
$min\left\{ \frac{cov_{qry}}{cov_{ref}}, \frac{cov_{ref}}{cov_{qry}}\right\}$.  (iv) The number of total
contigs were weighted as $\frac{1}{n_{contigs}}$ giving a chloroplast with 1 contig the optimal score.

\begin{equation}
  score = \frac{1}{4} \cdot \left( cov_{ref} +  cov_{qry} + min\left\{ \frac{cov_{qry}}{cov_{ref}}, \frac{cov_{ref}}{cov_{qry}}\right\} + \frac{1}{n_{contigs} }\right) \cdot 100
  \label{eqn:score_ass}
\end{equation}

While it is difficult to evaluate the success or failure of assemblies on a continuous scale, equation
\ref{eqn:score_ass} allows for objective and unbiased measurements. SNPs or other small variants do not
influence the outcome of the score, because it much more likely that they are due to in-species variation of
the plastid's genome and not caused be the assembly itself. Even if the latter is true it would be difficult
to determine.
  
\subsubsection{Consistency}
For any given bioinformatical application consistency is a desired trait. Software ideally should repeatedly
yield the same output when provided with the same output and assembly tools are exception.  To evaluate the
reproducibility of the the 7 tools all the 369 real data sets described in section \ref{sec:cp_real} were
assembled and scored twice for each assembler. The correlations between the first and the second run's scores
were used the measure the robustness of a program.

\section{Results} \label{results:ca}
\subsection{Quantitative}
\subsubsection{Simulated data}
\label{results:sim}

The simulated data sets were assembled and scored with all the tools as described above. Figure
\ref{fig:sim_tiles} shows a tile plot with their respective results. While at first sight there is no clear
correlation between the input data sets and the score, it is clearly visibile that there are grave differences between the
assemblers. Two programs namely \cassp \hspace{0.5ex} and \ioga \hspace{0.5ex} failed to correctly assemble a
single chloroplast genome. \ioga even fails to provide an output at all for the majority of the data sets. While
those two stand out as  negative examples \fp and \go stand out as a positive examples - perfectly or nearly
perfectly assembling all the data sets, with \go surpassing the performance of \fp. In the middle of the filed
are \ce, \oa and \np performing reasonably well, but sometimes lacking to solve the IRs and the circular
structure.


\begin{figure}[H]
\centering
\includegraphics[height=.55\textheight, width=.99\textwidth]{Figures/sim_tiles}
\decoRule
\caption[Score of assemblies of simulated data sets]{Results of assemblies executed with simulated data sets.}
\label{fig:sim_tiles}
\end{figure}

While there is a significant difference between the performance of the assemblers. Generally the other varying
input parameters, do have as grave an influence as the choice of assembler. While \fp deals with the shorter
reads of 150 bp much better than with the longer reads of 250 bp, the outcome of the other assemblies does not
seem to be influenced by the read length. There is no difference between the full and the subsampled data
sets. And while all assemblers appear to be more challenged by low chloroplast to core genome ratios of 1:10,
larger rations do not affect the quality of the assemblies.  Table \ref{tab:scores_simulated} shows all the
individual results for all data sets and assemblers. For the fields with no entry the respective assembler
failed to provide an output.

\begin{table}[ht]
\caption{Scores of assemblies of simulated data}
\label{tab:scores_simulated}
\centering
%\resizebox{\textwidth}{!}{
  \begin{tabular}{rlrrrrrrr}
 \hline
 & Data set & CAP & CE & FP & GP & IOGA & NP & oA \\ 
 \hline
 1 & sim\_150bp.0-1 & 79.10 & 100.00 & 99.48 & 100.00 & & 91.52 & 100.00 \\ 
 2 & sim\_150bp.0-1.2M & 79.10 & 100.00 & 99.72 & 100.00 & 79.10 & 91.52 & 91.50 \\ 
 3 & sim\_150bp.1-10 & & 56.44 & 100.00 & 76.98 & & 91.52 & 78.00 \\ 
 4 & sim\_150bp.1-10.2M & & & 99.97 & 100.00 & & 91.52 & 82.72 \\ 
 5 & sim\_150bp.1-100 & 75.72 & 100.00 & 99.48 & 100.00 & 66.09 & 91.52 & 91.50 \\ 
 6 & sim\_150bp.1-100.2M & & 100.00 & 99.47 & 100.00 & & 100.00 & 100.00 \\ 
 7 & sim\_150bp.1-1000 & 79.10 & & 99.72 & 100.00 & & 91.52 & 100.00 \\ 
 8 & sim\_150bp.1-1000.2M & 79.10 & 100.00 & 99.72 & 100.00 & & 91.52 & 100.00 \\ 
 9 & sim\_250bp.0-1 & 79.10 & 100.00 & 93.82 & 100.00 & & 91.52 & 91.50 \\ 
 10 & sim\_250bp.0-1.2M & 79.10 & 100.00 & 93.83 & 100.00 & & 91.52 & 91.50 \\ 
 11 & sim\_250bp.1-10 & & 54.98 & 68.45 & 78.89 & 52.71 & 91.52 & 40.20 \\ 
 12 & sim\_250bp.1-10.2M & & & 93.00 & 100.00 & 52.67 & 87.40 & 40.20 \\ 
 13 & sim\_250bp.1-100 & 72.81 & 100.00 & 93.82 & 100.00 & & 87.40 & 100.00 \\ 
 14 & sim\_250bp.1-100.2M & & 100.00 & 93.83 & 100.00 & & 87.40 & 100.00 \\ 
 15 & sim\_250bp.1-1000 & 79.10 & 21.30 & 93.83 & 100.00 & 76.96 & 91.52 & 91.50 \\ 
 16 & sim\_250bp.1-1000.2M & 79.10 & 100.00 & 93.83 & 100.00 & 67.55 & 87.40 & 100.00 \\
 \hline
\end{tabular}%}
\end{table}

\subsubsection{Real data sets}

Table \ref{tab:scores_real} summarizes the results from the assemblies of 369 data sets with 7
assemblers. Similar to the results of the previous section there is a significant difference between the
tools. Likewise \go is the most successful assembler by a large margin with 210 of 369 perfectly assembled
chloroplast genomes, completely failing to provide output for only 9 data sets, resulting in a median score >
99.  This is contradicting to \go, \cassp and \ioga, who failed to completely assemble a single genome. The
performance of \fp reasonably well im comparison, completing approximately half as many genomes as \go
and being the only other tool whose average score is larger than 90. Similar to the trials with the simulated
data in chapter \ref{results:sim} in the middle of the field are \ce, \hspace{0.5ex} \np \hspace{0.5ex} and
\oa.


\begin{table}[H]
\caption{Mean scores of chloroplast genome assemblers}
\label{tab:scores_real}
\centering
\begin{tabular}{rlrrrr}
  \hline
  & assembler & Median & IQR & N\_perfect & N\_tot \\ 
  \hline
  1 & CAP & 45.25 & 50.19 &  0 & 369 \\ 
  2 & CE & 56.55 & 71.50 & 14 & 369 \\ 
  3 & Fast-Plast & 92.80 & 23.59 & 113 & 369 \\ 
  4 & GetOrganelle & 99.83 & 20.94 & 210 & 360 \\ 
  5 & IOGA & 71.10 & 11.21 & 0 & 338 \\ 
  6 & NOVOPlasty & 75.95 & 48.69 & 58 & 369 \\ 
  7 & org.ASM & 67.35 & 91.69 & 46 & 348 \\ 
  \hline
\end{tabular}
\end{table}


Figure \ref{fig:swarm} emphasizes the large differences between the assemblers shown in table
\ref{tab:scores_real}. The swarm plots show distinct bands for some assemblers e.g. \np and \oa, suggesting
that multiple assemblies fail to be solved into a single contig genome at a certain point. As thoroughly
discussed in section \ref{dis_cp} solely from this swarm plot it is debatable if all the tools should be
recommended to be used for the purpose they were designed for.

\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/swarm}
\decoRule
\caption[Scores of assemblies from real data sets]{Box and swarm plots depicting the results from scoring shown caluculated by \ref{eqn:score_ass}}
\label{fig:swarm}
\end{figure}

\subsubsection{Consistency}

Consistency testing was done by re-running every assembly for the real data sets and comparison of the
scores. \ce was the only tool that was 100 \% consistent over both runs. Followed by \fp and \np. The
consistency plot figure \ref{fig:consisplot} for both of them results in an arrowhead shaped plot. With the
main differences between the first and second run in the best scores. All other assemblers appear to produce
the same output in the two runs except if either run failed to complete the assembly at all. This is less
pronounced for \cassp and \go and is a grave issue for \oa and \ioga.

\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/repro}
\decoRule
\caption[Comparison between two runs with the same assembler for consistency testing ]{Swarm plots depict the
  results from the scoring shown in \ref{eqn:score_ass} for two independent runs for each assembler on each of
  the data sets}
\label{fig:consisplot}
\end{figure}


\subsubsection{Novel}
 
The final assessments in the evaluation of the assemblers, were to test them on novel data sets without a
published chloroplast. This step is important for two reasons. (i) The possibility exists that certain tools
perform well on known chloroplasts because they have knowledge of their structure, which would lead to a lack
of generalization on unknown genomes.  (ii) To apply and test the gained insights with the goal of providing
the scientific community with a larger variety of published chloroplast genomes. As before the most successful
assembler was \go, with 49 out of 105 data sets completely assembled. \newline Lacking a reference genome for
alignment the success had to be defined differently and equation \ref{eqn:score_ass} was not suitable to
evaluate the novel assemblies. Metrics influencing the score of the novel assemblies were the number of
contigs, solving the IRs and the size of the SSC and LSC. This, known to the author, might be biased and not
true for all chloroplast and assumes that all chloroplast genomes evolved according to the general structure
described in chapter \ref{intro:cp}. Figure \ref{fig:upset_novel} compares the results of the assemblies with
at least one successful assembly.

\begin{figure}[H]
\centering
\includegraphics[height=.45\textheight, width=.95\textwidth]{Figures/upset_novel}
\decoRule
\caption[Upset plot comparing the success rates for novel data sets]{Upset plot comparing the success rates of the different assemblers}
\label{fig:upset_novel}
\end{figure}


\section{Discussion} \label{dis_cp}


Recapitulating the study presented in this chapter so far consists of two goals. (i) To assess the overallq
performance of a variety of tools designed specifically for the assembly of circular chloroplast genomes from
paired-end Illumina reads and (ii) to \textit{de novo} assemble a variety of yet unpublished chloroplast
genomes from existing data. To accomplish the first goal 16 simulated and 369 simulated data sets were used
adding up to a total of 5166 assemblies for the real data sets and 112 for the simulated data, along 735
assemblies for the novel data sets, thus underlying the statistical powers of this benchmarking study. The
most successful tools were \go \hspace{.5ex} and \fp \hspace{.5ex} which are recommended to be used
complementary, because as shown in figure \ref{fig:upset} they succeed for the most data sets compared to
other assemblers and accomplish to satisfactory assemble chloroplast genomes where the other fails. If both of
them fail it might be worthwhile to repeat the runs because other results could be expected as shown in the
scatter plots of figure \ref{fig:consisplot}, especially \fp might be able to improve the previously achieved
sore. Only if both of them fail it might, even though improbable, that \np might lead to a successful
assembly. The other assemblers should be used with caution. While \ce might be good for a quick overview due
to its relatively low demand in computational time \cite{freudenthal2019landscape}; \cassp, \oa and \ioga are
not be recommended to used as the primary tools in organelle genome assembly projects, as used in this study.

\begin{figure}[H]
\centering
\includegraphics[height=.65\textheight, width=.99\textwidth]{Figures/upset}
\decoRule
\caption[Upset plot comparing the success rates of of all assemblers]{Upset plot showing the intersections of
  success rates between assemblers. A successful assembly was defined with a score > 99 according to equation
  \ref{eqn:score_ass}. The colored, horizontal barplot indicates the total number of successful assemblies for
  an individual tool. The black, vertical barplot gives the magnitude of the intersection between the
  assemblers indicated with the dot. Therefore there first bar is to be interpreted as follows: 77 data sets
  were only successfully assembled by \ce, likewise 48 genomes were assembled completely by \go \hspace{0.5ex}
  and \fp \hspace{0.5ex} and so on. }
\label{fig:upset}
\end{figure}


It might be possible that overall performance of a specify tool might change significantly by fine tuning the
input parameters of the tool, which was purposely not done in the scope of the present study, because this
study was designed to mimic the behavior have end-users and not developers of such tools and the assumption is
proposed that end-users with little experience in bioinformatics would be inclined to use the basic
configurations of such a tool.


While there is a huge differences for all assemblers they are presented with the same challenges and the
bottlenecks are similar for each of them, the success rate of passing those differs however. Figure
\ref{fig:alitv} shows the alignment of the 7 chloroplast genomes of \textit{Oryza brachyantha} a grass
distantly related to cultivated rice \textit{Orayza sativa} and the respective reference genome. For the need
of a linear representation of the circular genome the convention is to present chloroplast genomes in the
order LSC - IRa - SSC -IRb. \textit{O. brachyantha} was chosen because multiple tools successfully or at least
almost assembled the full genome. Only \cassp is singled out, which only managed to assemble a few fragments
on the SCC and the IRs on many contigs. A common mistake is to return 3 contigs as \ioga \hspace{.5ex}
did. They represent the LSC the SSC and one IR but failed to resolve those regions into a one circular
contig. \go \hspace{.5ex} and \fp \hspace{.5ex} were able to reproduce the structure of the reference, while
\ce \hspace{.5ex} flipped the LSC and \np  and \oa \hspace{.5ex} were not able to construct the single contig
into the conventional structure. All of this are common mistakes appearing more or less rare in all the
assemblers. This could be a good starting point for the developers to further improve their tools. In this
example all but \cassp \hspace{.5ex} were able to construct all the parts of the chloroplast's genome, and the
main mistake was to resolve the structure of the genome into a circular, one contig version.


\begin{figure}[H]
\centering
\includegraphics[height=.60\textheight, width=.99\textwidth]{Figures/AliTV.png}
\decoRule
\caption[AliTV plot of alignments of assemblies of \textit{Oryza brachyantha} of all assemblers]{ AliTV plot
  \cite{alitv} from \cite{freudenthal2019landscape} showing the alignments of \textit{Oryza brachyantha}
  chloroplast genomes fro all 7 assemblers. Regions in adjacent assemblies are connected with colored ribbons
  for similar regions in alignment with the identity coded as described in the legend. The purple arrows
  indicate the IR regions}
\label{fig:alitv}
\end{figure}

\section{Conclusion \& outlook}

Organelle genomics is promising field in plant genetics. As described in section \ref{intro:cp} chloroplast
genomes are well-suited for applications in evolutionary sciences, taxonomy and barcoding applications. Alike
its mother branch genomics for comparative chloroplast genomics its just as crucial to obtain high quality
genomes. And the quality is mainly influenced by two major factors: the quality of the genome sequencing
protocol and the quality of the assembly. As shown the latter varies massively between tools and not all tools
are recommend equally from the conclusions drawn for the above experiments. All tools have room for
improvement, this is meant to criticize the respectable work of the developers, but to encourage them to
further develop tools and publish them under terms of liberal software licenses for the greater benefit of the
entire scientific community.
