\chapter{Genomic prediction of phenotypic values of quantitative
  traits using artificial neural networks}

\label{Chapter3} % For referencing the chapter elsewhere, use \ref{Chapter1} 


\section{Introduction to machine learning}
\subsection{A brief history of machine learning} \label{introml}
\subsubsection{The basic perceptron model}

While machine learning, neural networks and deep learning became essential tools for many
applications in more recent years, their mathematical principals date back to the early
1950s and 1960s. Figure \ref{fig:perceptron} schematically shows the basic perceptron
model as proposed by Rosenblatt, one of the founders of machine learning, as the set of
related statistical algorithms would be defined today. Rosenblatt designed his perceptron
to mimic the information flow in biological nervous systems \cite{rosenblatt1961}.

\begin{figure}[th]
  \centering \includegraphics[height=.25\textheight, width=.5\textwidth]{Figures/perceptron.png}
  \decoRule
\caption[Basic perceptron model]{Basic perceptron model as proposed by Rosenblatt \cite{rosenblatt1961}}
\label{fig:perceptron}
\end{figure}


This basic perceptron, which contrary to perceptrons used nowadays, does not have an
embedded activation function, takes $n$ binary inputs $x_1 , x_2 .... x_n$ and produces a
single, likewise binary, output $y$ after being processed. To achieve this Rosenblatt
introduced the concept of weights, which determine a certain input's relative importance
to the outcome of the output $w_1 , w_2 ... w_n$. The output $y$ is determined by the
weighted sum of the weights $\sum_i w_ix_i $. If a certain threshold value is met the
neuron is either activated and outputs 1 or not activated resulting in and output of
0. This is algebraically represented in equation \ref{eqn:weights}:

\begin{subequations}
 \begin{align}
  0 = \mbox{if } \sum_i^n w_i x_i - \theta \leq 0 \\
  1 = \mbox{if } \sum_i^n w_i x_i - \theta > 0
 \end{align}
 \label{eqn:weights}
\end{subequations}


Next to the weights $w_n$ and the inputs $x_n$, a third term $\theta$ is introduced in
equation \ref{eqn:weights}, which represents the activation threshold. A single perceptron
is a linear classifier and can only be trained on linearly separable functions and can be
applied, as shown by \cite{rosenblatt1961}, to solve simple logical operations as AND, OR
and NOT. The basic perceptron fails, however, due to non-linearity to perform XOR
operations, which was proven by \cite{marvin1969}. This discovery led to a near
stillstance in the research of artificial neural networks in the 1970s. That time period
is now often referred to as the first AI-winter. Another reason that massively hindered
the applications and research of machine learning during that span was the, compared to
modern times, incredibly small amount of computational power available \cite{nguyen1990truck}. \\
More complex decision making, like solving XOR problems, requires more complex structures
than a single perceptron can provide. Continuing the trend of mimicking human neural
networks, multiple artificial neurons were stacked into layers and these layers were
connected to each other allowing communication between the many perceptrons in such a
network. Figure \ref{fig:nn} schematically shows the basic structure of an artificial
neural network, now harboring three types of layers.
\begin{enumerate}[(i)]
\item the input layer
\item one or more hidden layers
\item the output layer, which in this case only consists of one neuron
\end{enumerate}

\begin{figure}[H]
\centering
\includegraphics[height=.25\textheight, width=.5\textwidth]{Figures/neuralnet}
\decoRule
\caption[Schematic layout of a simple multi-layer perceptron]{Schematic layout of a simple multi-layer perceptron}
\label{fig:nn}
\end{figure}


In the sample layout of figure \ref{fig:nn} the neurons in the first column weigh the
inputs and pass the gathered information to the neurons into the second layer. In the case
above neurons in the first layer are connected to all neurons on the second layer. Such
layers are referred to as fully-connected layers (FLC) and their resulting networks are
often called multi-layer perceptrons (MLP) or fully-connected networks. This architecture
enables the network to perform more complex calculations resulting in more abstract
decision making than single neurons or single layer architectures.\\
There are other architectures, where neurons in the previous layer are only connected with
neighboring neurons in the succeeding layers. Those are known as locally-connected layers
(LCL). Related to them are convolutional layers which share weights between selected
neurons, building convolutional neural networks (CNN) \cite{lecun1999object}.

\subsubsection{Activation functions}

The neurons discussed so far are only capable of outputting binary results, depending on
whether threshold values are being reached or not. For more complex estimations it is
desirable that small changes in the input also result in small changes of the output. This
requirement cannot be easily met with binary outputs. Activation functions for a given
node provide more sophisticated rules for the output in accordance to their inputs
\cite{vzilinskas2006practical}.

\begin{figure}[H]
\centering
\includegraphics[height=.55\textheight, width=.85\textwidth]{Figures/activation}
\decoRule
\caption[Popular activation functions for neural networks]{Popular activation functions used in
  neural networks.
  \textbf{A} Binary step activation function \\
  \textbf{B} Identity activation function \\
  \textbf{C} Sigmoid or logistic activation function \\
  \textbf{D} tangens hyperbolicus activation function \\
  \textbf{E} rectified linear units activation function \\
  \textbf{F} SoftPlus activation function\\}
\label{fig:activation}
\end{figure}


Figure \ref{fig:activation} shows six of the most commonly used activation functions
\cite{warner1996understanding}. The simplest one, the binary step activation was already
introduced (function \textbf{A} in equation \ref{eqn:binary}), which properties have been
discussed along the perceptron model. All other activation functions produce continuous outputs from given inputs. \\
Next to the binary step function any mathematical function is able to serve as an activation
function in neural nets, starting with a simple identity function (equation
\ref{eqn:ident}, figure \ref{fig:activation} \textbf{B}). The sigmoid function (figure
\ref{fig:activation} \textbf{C}, equation \ref{eqn:sigmoid}) and tanh (figure
\ref{fig:activation} \textbf{D}, equation \ref{eqn:tanh}), when $x \rightarrow \infty$ or
$x \rightarrow -\infty$ have similar properties as the binary function, but produce
continuous output around threshold values of 0.

\begin{equation}
 f(x)= \sigma(x) = \left\{
 \begin{array}{ll}
 0 \; for \; x < 0 \\ 
 1 \; for \; x \geq 0
 \end{array}
\right .
\label{eqn:binary}
\end{equation}

\begin{equation}
 f(x) = \sigma(x) = x
 \label{eqn:ident}
\end{equation}
    
\begin{equation}
 f(x) = \sigma(x) = \frac{1}{1+e^{-x}} 
 \label{eqn:sigmoid}
\end{equation}

\begin{equation}
 f(x) = \sigma(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
 \label{eqn:tanh}
\end{equation}

\begin{equation}
 f(x)= \sigma(x) = \left\{
 \begin{array}{ll}
 0 \; for \; x < 0 \\ 
 x \; for \; x \geq 0
 \end{array}
\right .
\label{eqn:relu}
\end{equation}

\begin{equation}
 f(x) = ln(1+e^x)
 \label{eqn:softplus}
\end{equation}


Rectified linear units (ReLU) (equation \ref{eqn:relu}) and SoftPlus (equation \ref{eqn:softplus}) share
similar properties as well, the latter one being a smoothed version of ReLU. Rectifiers as
activation functions have been introduced in the 2000s \cite{hahnloser2000digital} and
have since then overtaken all others as the most popular activation functions in neural
networks and deep learning \cite{lecun2015deep}. They have proven to be superior in many
deep-learning applications over sigmoid or logistic functions. One of the advantages
leading to the superiority of ReLUs is that with randomly initialized weights only half of
the ReLU neurons are activated at start compared to tanh and sigmoid activation
\cite{glorot2011deep}. All activation functions shown in figure \ref{fig:activation}, but
the binary step function, share one common property: a small change of the input weight
will result in small changes of the output, while a small change of the input for the
binary step function leads to either no or a complete change of the output, except for
ReLU when
$x<0$. This property is, as described below, is an important prerequisite for networks being able to learn. \\

\subsubsection{Gradient descent algorithm}

Let a network alike the one shown in figure \ref{fig:nn} be designed for the
classification of an arbitrary, binaray phenotype like petal color, being blue or not, with $x_1 \dots x_4$ on the
input layers being genetic markers as features. The output layer displays value from 0 to
1 giving the probability of the petals being blue or not. To quantify how well the network
performs on predicting the color of the petals a loss
function is applied \cite{schmidhuber2015deep}. \\
There is a large variety of different loss functions available for neural networks like
mean squared error (MSE), root mean squared error (RMSE) and cross-entropy among
others. In general MSE and RMSE are used for regression problems, with the latter being
less popular, and cross-entropy also called log-loss is used for binary or multi-class
classification settings \cite{janocha2017loss}. Since all problems presented in due course
are regression problems that use MSE as their loss function this will be the only loss
function further elaborated upon. MSE or the quadratic loss function can be written as:

\begin{equation}
 MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
 \label{eqn:MSE}
\end{equation}

Equation \ref{eqn:MSE} shows the MSE function, which is the sum of the squares of the
differences of all the predicted $\hat{y}_i$ and the real values $y_i$. The same function
can be rewritten with the previously used terminology of weights and biases in equation
\ref{eqn:MSE} with $L(w,b)$ as the loss.

\begin{equation}
  L(w,b) = \frac{1}{2n} \sum_x \| y(x) - y|^2.
 \label{eqn:MSE2}
\end{equation}


With $w$ and $b$ as the collection of all the weights and the biases in the network used
to optimize the function $y(x)$. Giving the quadratic nature of the function $L(w,b)$ will
always be non-negative. If $L(w,b) \rightarrow 0$ the loss is minimal, meaning
that the real and predicted values are close together and the network found weights and biases that approximate the output well. \\
A widely used algorithm to find the optimum of a loss function by finding its global
minimum is gradient descent (GD) \cite{bottou1991stochastic}. The idea behind GD or other
optimization algorithms is to start with randomly initialized weights and biases and
repeatedly move them in direction $\Delta w$ and $\Delta b$. This results in a change of
the loss function which can be represented using partial derivatives as shown in equation
\ref{eqn:deltaL}.

\begin{equation}
  \Delta L = \frac{\partial L}{\partial w} \Delta w + \frac{\partial L}{\partial b} \Delta b
\label{eqn:deltaL} 
\end{equation}

Ideally $\Delta L$ is negative and the optimization algorithm found $\Delta w$ and
$\Delta b$ that lead to a reduction of the loss. To simplify this problem let $\Delta d$
be the vector of changes: $\Delta d = (\Delta w , \Delta b)^T $ and $\nabla L$ the vector
of the partial derivatives as in equation \ref{eqn:nabla}.


\begin{equation}
 \nabla L = \left(\frac{\partial L}{\partial w}, \frac{\partial L}{\partial b}\right)^T
\label{eqn:nabla}
\end{equation}

Having defined $\nabla L$ and $\Delta d$ the term \ref{eqn:deltaL} can be simplified to:

\begin{equation}
\Delta C = \nabla L * \Delta d
 \label{eqn:cd}
\end{equation}

Now the task of gradient descent is to find $\Delta d$ that results in $\Delta C$ being negative as
shown in equation \ref{eqn:eta}

\begin{equation}
 \Delta d = -\eta \nabla L
 \label{eqn:eta}
\end{equation}

Here $\eta$ is a small positive decimal number, commonly referred to as the learning rate,
which usually, but not exclusively, ranges from 0.1 to 0.001.  Having found a way to
ensure that $\Delta L$ is always negative according to equation \ref{eqn:eta} it can be
utilized to repeatedly update the gradient $\nabla L$ over time steps $T$. To make the
gradient descent algorithm efficient the learning rate $\eta$ has to be chosen
correctly. If $\eta$ is too large the gradient $\Delta L$ possibly ends up being larger
than zero leading to an increase of the loss. If the learning rate is too small
convergence will either take too long or not take place at all
\cite{bergstra2011algorithms}. In practical machine learning approaches different learning
rates are tested. There are also a variety of algorithmic approaches available to select
the learning rate. Equation \ref{eqn:nabla} only accounts for two inputs features but it
can be generalized to compute $n$ inputs as shown in equation \ref{eqn:gd}.

\begin{eqnarray}
  \nabla L = \left(\frac{\partial L}{\partial w_1}, \ldots ,
  \frac{\partial L}{\partial w_n}\right)^T
 \label{eqn:gd}
\end{eqnarray}

Equation \ref{eqn:gdwb} shows the gradient descent how it is used to repetitively update
the weights and biases to optimize the loss function $L(c,w)$ with $w$ and $b$ as the
weight and bias matrices and the learning rate $\eta$. In machine learning each
iterational update of the network is often called epoch or training epoch.

\begin{subequations}
 \begin{align}
  w = w_i - \eta \frac{\partial}{\partial w}L(w) \\
  b = b_i - \eta \frac{\partial}{\partial b}L(b) 
 \end{align}
 \label{eqn:gdwb}
\end{subequations}

Substituting the partial differentials with $\nabla L$ equation \ref{eqn:gdwb} a and b likewise simplifies to:

\begin{equation}
 w = w_i - \eta \nabla L
 \label{eqn:simplegd} 
\end{equation}

\subsubsection{Optimizers}
The previous section introduced the concept of gradient descent, an algorithm to minimize
the loss function of the weights and biases of a neural network. All other optimizers
introduced in
the following chapter are either variations or extensions of the basic gradient descent algorithm shown in equation \ref{eqn:gdwb}. \\
One disadvantage of gradient descent is that if the data set grows larger the demand in
memory for computation increases exponentially. Taking into consideration that machine
learning is a popular method in big data applications this is a serious drawback.\\
Methods to solve that issue are stochastic gradient descent and mini batch gradient
descent. The idea behind the latter is to randomly divide the entity of the training data
into subsamples called mini batches \cite{bottou-bousquet-2008}. The network is then
trained iteratively with all mini batches. The batch size has a significant influence on
the accuracy and the training speed of the network and is a hyperparameter, which has to
be tuned by iteratively testing different settings. If
the batch size is one, mini batch GD is also referred to as stochastical gradient descent (SGD). \\
During the optimization process optimizers can descent into local minima of the cost
function without being able to overcome them enabling to reach the global minimum. An
algorithm extending GD to accelerate the search of the global minimum is momentum, which
allows the GD to speed up when the loss is decreasing and to carry on even when the loss
function $L(w,b)$ is temporally increasing. This is achieved by accounting for the
gradient of the previous step in the calculation of the current step. This concept was
introduced by \cite{polyak1964} and re-popularized alongside the introduction of
backpropagation learning by \cite{rumelhart1988learning} an algorithm to efficiently
update the weights and biases.

\begin{equation}
 w = w_i - \eta \nabla L + \alpha \Delta w
 \label{eqn:momentum}
\end{equation}

Equation \ref{eqn:momentum} shows how the momentum is mathematically represented in GD to
update the weights $w$ or likewise the biases. The delta of the weights multiplied by an
coefficient $\alpha$ is the momentum. $\alpha$ usually ranges from 0.1 to 0.9 and is
another parameter to be tuned for successful training. If the momentum is too small the GD
will not be able to overcome local minima and if $\alpha$ is too large the loss functions tends to oscillate without ever finding an optimum \cite{lecun2015deep}. \\
For both the momentum and the learning rate it is impractical to maintain the same level
during all training epochs. After each epoch the loss function is either closer or further
away from its global minima and depending on the distance to that minimum it is desirable
to have larger or smaller learning rates and momenta. This can be achieved with naive
approaches, for example using a step function to gradually decrease those values after
each iteration or to utilize algorithmic approaches \cite{michie1994machine}. There is a
large variety of optimizers trying to find optimal values for $\alpha$ and $\eta$ and till
today this field is under active research \cite{goodfellow2016deep}. Popular among those
are: RMSprop \cite{hinton2012neural}; Nesterov momentum \cite{dozat2016incorporating};
Adadelta \cite{zeiler2012adadelta}; Adagrad \cite{ruder2016overview} and Adam
\cite{kingma2014adam}. With Adam being the most popular
optimizer today. \\
Nesterov momentum is a slight change to the normal momentum algorithm, capable of having huge impacts in practical applications because it helps avoiding oscillations around the minimum by using intermediate information to adapt the momentum. \\
RMSProp - root mean square propagation - is a method aiming to adapt the learning rate
algorithmically by choosing $\eta$ for each iteration. Lastly, the wide-spread Adam
optimizer combines both of the features of momentum and RMSProp and adapts the learning
rate as well as the momentum iteratively \cite{kingma2014adam}.

\subsubsection{Regularization parameters and overfitting}

A common problem in machine learning is to over parameterize the model on the training data
and losing the ability to generalize on validation data. This issue occurs because neural
networks have hundreds of thousand of free parameters to be trained. Deeper neural
networks even have billions or trillions of parameters. If training of the neural net
continues for enough epochs eventually the loss function will approach a minimum. As
$ L(w,b) \rightarrow 0 $ the initially drawn conclusion could mislead to assuming that
training was successful. However, when trying to apply the trained network on the training
data set (TRN) to a testing data set (TST) or validation set (VAL) the loss of TST is very large and the accuracy
of prediction of TST is accordingly small. This phenomenon is known as overfitting and a
lot of fine tuning of hyperparameters is devoted to minimizing this effect
\cite{tetko1995neural}. Figure \ref{fig:overfitting} visualizes this  during
training \cite{goodfellow2016deep} of a neural network.

\begin{figure}[H]
  \centering \includegraphics[height=.35\textheight, width=1.0\textwidth]{Figures/overfitting}
  \decoRule
  \caption[Training vs. validation loss over time]{Learning curves showing how a loss function
    changes during training in the training and validation data set. While the training loss
    approaches 0 the validation loss starts increasing after hitting a minimum. This effect is due
    to overfitting on the training data set. Figure from \cite{goodfellow2016deep}.}
 \label{fig:overfitting}
\end{figure}

\textbf{Cross-validation} \\

A method that is used in basically every training of neural networks is splitting up the
data in multiple subsets. More specifically in a training set (TRN) and a testing set
(TST). The training set is used to minimize the loss functions and its success is
evaluated by comparison of the predicted values $\hat{y}$ and the real
values in TST $y$. For all neural nets in this study Pearson's correlation coefficients
were chosen as performance metric, calculated according to equation \ref{eqn:pearson}
\cite{soper1917distribution}.

\begin{equation}
  \rho(y,\hat{y}) = \frac{cov(y,\hat{y})}{ \sigma_y \sigma_{\hat{y}}}
 \label{eqn:pearson}
\end{equation}

There are other popular performance metrics, especially for classification problems, like
AUC (area under the curve) and ROC (receiver operating characteristics), which evaluate
the success of learning by weighing sensitivity and specificity. \\
In cross-validation compared to single validation the initial data set is split into TRN
and TST multiple times, e.g. if the ratio is 80:20 five times, and each TRN-TST pair is
evaluated individually. Sometimes it is necessary to use a third subset - the validation
data set. Because hyperparameter tuning is performed with the TRN and TST sets, a third
portion of the data is needed to asses whether the neural network is able to generalize on
global data or not.

% \textbf{L1 and L2 loss} \\
 
% L1 and L2

% \textbf{Dropout}
\newpage
\section{Introduction to genomic selection} \label{chap:gs}
\subsection{On the nature of quantitative traits} \label{quan}

According to the omnigenic model, which is an extension of the polygenic model, proposed
by \cite{boyle2017expanded} and thoroughly reviewed in \cite{timpson2018}, all traits or
phenotypic values are influenced by a great number or even all genes in the genome. This
therefore results in traits following gradual statistical distributions instead of being
binned in classes or
binary.\\
Intuitively, this might be contradicting to the theoretical foundation of modern genetics
- Mendel's three laws. They were derived from observations, which were mainly influenced
by one locus. Using one of Mendel's phenotypes as an example - the round or wrinkled
surfaces of peas (\textit{Pisum sativum})- an assessment of a couple of thousand peas
would inevitably lead to the conclusion that from the ``roundest'' to the ``wrinkliest''
pea any gradual step between those two classes is
possible and observable. \\
Mendel's third law of independent segregation also only holds true under certain
assumptions. The simplest one being that the traits under investigation have to be located
on different linkage groups, otherwise the seven traits used in Mendel's initial studies
would not have segregated independently. The odds of seven randomly selected traits being
on seven different linkage groups are rather small, especially taking into account that
the genome of the \textit{P. sativum} consists of only seven chromosomes itself
\cite{kalo2004}. Mendel most likely knew about traits not following his own laws, as well
as being aware of the quantitative nature of traits such as the constitution of pea's
surface or the color of its petals. However, being the pioneer of a then rather unexplored
field of science, some of whose big questions we fail to satisfactory answer today, he did
not have
the resources or the knowledge to explain traits that were not ``mendeling''. \\
Initially thought to be contradicting to Mendel's ideas, Darwin proposed the concept of
evolution due to natural selection, which introduced the idea of traits following gradual
distributions \cite{darwin1859}. This contrast led to a long lasting debate in the
scientific community in the early 1900s between the Mendelians and the biometricians, who
believed in the quantitative nature of continuous traits. This conflict has eventually
been solved by Fisher's fundamental work published in 1919 \cite{fisher1919xv}. His
theories combined the then in all fields of science popular research on statistical
distributions and genomics. He mathematically proved that traits influenced by many genes,
with randomly-sampled alleles, follow a continuous normal distribution in a
population. \\
While this combined the ideas of Mendel and of the biometricians it opened another long
debated question of effect sizes and the overall genetic architecture of complex
traits. While in the theory of monogenic traits the effect size of the single gene on the
trait is 100\%, with an increasing number of genes influencing a complex trait the
\textit{per se} contribution of single genes has to decrease with an increasing number of
loci determining the value of a given trait. Until the 1990s it has been believed that
complex traits are predominantly controlled by few genes with a
large to medium effect size, while others supposedly have a minimal influences \cite{zhang2018esti}. \\
With the upcoming popularity of GWAS as the favored method to decipher genetic
architectures of traits, having pioneered in human genetics, it became clear that the
majority of effect sizes are tiny (< 1\%), while there are very few loci which have a
moderate effect on the phenotypic variance of a population with around 10\% or less
\cite{stringer2011}; \cite{korte2013advantages}. This nature of quantitative traits
presents great challenges to animal \cite{goddard2009} and plant breeding
\cite{wurschum2012} in further improving crop or livestock performances, as well as
complicating the decomposition of genomic causes for diseases like schizophrenia or autism in human medicine \cite{de2014}; \cite{purcell2014}. \\
While the complex nature of the architecture of quantitative traits provides enough
challenges as is, all traits are also influenced by the environment surrounding the individual.\\
Therefore the distribution of trait values in a given population can be expressed as the
addition of the variances of its genetic and the environmental effects \ref{eqn:PGE}.

\begin{equation}
 \sigma_{P} = \sigma_{G} + \sigma_{E}
 \label{eqn:PGE}
\end{equation}

The genomic and the environmental effects do not only influence the phenotypic variance directly, but
the environment also has an influence on gene expression, methylation of DNA bases etc. and
therefore the equation \ref{eqn:PGE} extends by the variance of the gene-environment
interactions $\sigma_{GxE}$  to equation \ref{eqn:PGGE}  \cite{lynch1998}; \cite{walsh2018}.
    
\begin{equation}
 \sigma_{P} = \sigma_{G} + \sigma_{E} + \sigma_{GxE}
 \label{eqn:PGGE}
\end{equation}

Equation \ref{eqn:PGGE} shows the decomposition of the phenotypic variance. To thoroughly
understand the complex genetic architectures of traits the genetic variance needs to be
decomposed further in its additive, dominance and epistatic components as in equation
\ref{eqn:GAD}.

\begin{equation}
 \sigma_{G} = \sigma_{A} + \sigma_{D} + \sigma_{I}
 \label{eqn:GAD}
\end{equation}

The additive effects are caused by single, for this model mostly homozygous, loci while
the variance due to dominance effects is caused by heterozygous loci with their
resulting interactions being full-, over- , co- or underdominant. Lastly, the interaction
effects are a result of two or more genes only having an impact if they co-occur in a
certain state. The resulting variance is commonly known as the gene-gene interaction or epistasis \cite{falconer1996}. \\
Since possible interactions in a genome can appear between additive or dominant or a
combination of those loci, the variance due to interaction effects $\sigma_{I}$ can be
further dissembled into the variances resulting from additive-additive $\sigma_{AA}$
dominant-dominant $\sigma_{DD}$ and additive-dominant $\sigma_{AD}$ interactions as shown
in equation \ref{eqn:IAA}.

\begin{equation}
 \sigma_{I} = \sigma_{AxA} + \sigma_{DxD} + \sigma_{AxD}
 \label{eqn:IAA}
\end{equation}

Knowledge of the variance components involved in the expression of a trait in a given
population leads up to the estimation of the total influence of all genetic variances and
the environmental variance on the phenotypic distribution. This concept is called
heritability. \\
The heritability of a trait $H^2$ accounts for the proportion of the phenotypic variance
controlled by the total genetic variance as shown in equation \ref{eqn:h2G}. This is also
referred to as broad sense heritability because all genetic effects, including additive,
dominance and epistatic effects, are included \cite{brooker1999genetics}.

\begin{equation}
 H^2 = \frac{\sigma_{A} + \sigma_{D} + \sigma_{I}}{\sigma_{P}}
 \label{eqn:h2G}
\end{equation}

The concept of narrow-sense heritability \ref{eqn:h2a} is similar to the broad-sense
heritability, but only the additive genetic effects are included in the equation. This
differentiation is important for natural and artificial selection and thus is commonly used
in evolutionary genomics and breeding. Because in diploid species each parent only passes
down a single allele of a given locus, dominance effects or interaction effects are
not commonly inherited from one parent. Therefore mainly the additive genetic effects of a
parent influence its offspring. While the dominance and epistatic variances are controlled
by the combination of the parents \cite{falconer1996}, \cite{walsh2018}.

\begin{equation}
  h^2 = \frac{\sigma_{A}}{\sigma_{P}}
 \label{eqn:h2a}
\end{equation}

\subsection{Artificial selection in plant and animal breeding in the genomics era}
\subsubsection{Introduction to genomic selection } \label{intro:gs}

Genomic prediction has been applied to almost all relevant crop and model species. This
includes among others: \\
\textit{A.thaliana}; \cite{shen2013novel}; \cite{hu2015}.\\
Alfalfa (\textit{Medicago sativa}) \cite{li2012applied}; \cite{annicchiarico2015accuracy}; \cite{li2015genomical}; \cite{biazzi2017genome}; \cite{hawkins2018recent}. \\
Barley (\textit{Hordeum vulgare}) \cite{zhong2009factors}; \cite{oakey2016}; \cite{neyhart2019}. \\
Cassava (\textit{Manihot esculenta}) \cite{elias2018}; \cite{elias2018improving}.
Cauliflower (\textit{Brassica oleracea spp.}) \cite{thorwarth2018genomic}.\\
Cotton (\textit{Gossiypium spp.}) \cite{gapare2018}.\\
Maize (\textit{Zea mays}) \cite{rincent2012}; \cite{windhausen2012};
\cite{technow2013genomic}; \cite{riedelsheimer2013genomic}; \cite{guo2013accuracy};
\cite{peiffer2014genetic}; \cite{technow2014genome}; \cite{lehermeier2014usefulness};
\cite{owens2014foundation}; \cite{montesinos2015threshold}; \cite{bustos2016improvement};
\cite{kadam2016genomic}; \cite{schopp2017accuracy};\cite{schopp2017genomic};
\cite{e2017genomic}; \cite{brauner2018genomic};
\cite{schrag2018beyond}; \cite{moeinizade2019}; \cite{allier2019usefulness}. \\
Potato (\textit{Solanum tuberosum}) \cite{enciso2018genomic}; \cite{Endelman2018pot}.\\
Rape seed (\textit{Brassica napus}) \cite{snowdon2012potential}; \cite{wurschum2014potential}; \cite{qian2014sub}; \cite{jan2016genomic}; \cite{luo2017genomic}; \cite{werner2018effective}.\\
Rice (\textit{Oryza sativa})  \cite{Xu2013rice}; \cite{Grenier2015}; \cite{BenHassen2018}; \cite{Momen2019}. \\
Rye (\textit{Secale cerale}) \cite{bernal2014importance}; \cite{wang2014accuracy};
\cite{auinger2016model}; \cite{marulanda2016optimum}; \cite{bernal2017genomic}.\\
Sugar beet (\textit{Beta vulgaris}), \cite{wurschum2013genomic}; \cite{biscarini2014genome}.\\
Sugar cane (\textit{Saccharum officinarum}) \cite{gouy2013experimental}.\\
Soybean (\textit{Glycine max}) \cite{Jarquin_2016}; \cite{Xavier_2016}; \cite{Stewart_Brown_2019}.\\
Switchgrass (\textit{Panicum virgatum}) \cite{Ramstein_2016}; \cite{Poudel_2019}; \cite{Ramstein_2019}. \\
Wheat (\textit{Triticum aestivum}) \cite{Thavamanikumar_2015}; \cite{Lopez_Cruz_2015};
\cite{Sukumaran_2016}; \cite{Bustos_Korts_2016}; \cite{Gianola_2016_wheat};
\cite{Crossa_2016_wheat}; \cite{Rincent_2018}; \cite{Norman_2018}; \cite{Belamkar_2018};
\cite{Ovenden_2018}; \cite{Cuevas_2019}; \cite{Howard_2019}; \cite{Krause_2019}. \\
As well as various tree species \cite{Holliday_2012}; \cite{Resende_2012}; \cite{Zapata_Valenzuela_2013};  \cite{Jaramillo_Correa_2014}; \cite{Kumar_2015}; \cite{GamalElDien_2016}; \cite{Ratcliffe_2017}; \cite{Rincent_2018}; \cite{Kainer_2018}; \cite{deAlmeidaFilho2019}. \\
Even though GS finds broad application in plant breeding it has been originally developed
for the use in animal breeding \cite{hayes2010genome}; \cite{goddard2011using}. The gold
standard is a method known as genomic BLUP \cite{vanraden2008efficient}, which utilizes a
relationship matrix based on the co-occurrence of genetic markers. This method is derived
from the pre-genomic era in animal breeding, where the relationship matrix was constructed
after pedigrees according to the best linear unbiased predictors (BLUP) based on the
linear mixed
model equations developed by \cite{henderson1975best}. \\
Genomic BLUP (GBLUP) accounts only for additive-genetic effects
\cite{vanraden2008efficient}. There are other methods that are able to account for more
complex genomic effects that are non-additive. Popular among those are for example
Reproducing Kernel Hilbert Spaces (RKHS) \cite{gianola2008reproducing}. Alternatively to
Henderson's linear mixed models, a large variety of different Bayesian methods for genomic
prediction became popular \cite{hayes2001}; \cite{gianola2009}; \cite{habier2011};
\cite{gianola2013}; \cite{crossa2017}.

\subsubsection{Genomic prediction in recurrent selection and the breeders equation}

While the quantitative genetic methods breeders utilize are complex their goals can be
defined in one sentence: genetically improve plant germplasms for agriculture. The
breeding process started at the same time as farming around 10,000 BC in the region
between the Euphrat and Tigris rivers known as the fertile crescent
\cite{kingsbury2009hybrid}. This changed the phenotypic appearance of the early crops
dramatically to the point where they share little external traits with their wild
ancestors. Those changes have been deeply carved into the genomes, which underwent serious
alterations, including hybridization, duplications etc. This lead to most crop plants not
having any wild ancestors with whom they could naturally mate. For example wheat
(\textit{T. aestivum}), one of the three most important sources of food on a global
scale, underwent multiple hybridization steps \cite{ozkan2001allopolyploidy}. Wheat is a
hybrid from either the diploid emmer (\textit{T. diccoides}) or durum wheat
(\textit{T. durum}) and \textit{{Aegilops tauschii}}, while emmer and durum are hybrids
derived from wild emmer, which is a hybrid of a wild grass of the genus of \textit{Aegilops}
and \textit{T. urata} \cite{friebe2000development}; \cite{feldman2012genome}.\\
While being ignorant of modern genetics early ``plant breeders'' must have had an
intuitive, yet naive, understanding of the general concept of heritability in a way that
they must have comprehended that offsprings share properties with their parents, which
motivated them to regrow individuals with desired traits generation after
generation. This induced many changes including that artificial selected plants are
commonly largely inbred. That process could be considered an early form of recurrent
truncation selection. Truncation selection on a normal distributed phenotype is shown in
figure \ref{fig:trunSel}.
 
\begin{figure}[H]
  \centering \includegraphics[height=.25\textheight, width=0.6\textwidth]{Figures/truncSel} \decoRule
  \caption[Truncation selection of a normal distributed phenotype]{Truncation selection
    from a normal distributed phenotype with selection a threshold value of $T$, $\mu$ as
    the mean of the total population and $\mu^{\ast}$ as the mean of the selected
    phenotypes. Graphic from \cite{walsh2018short}}
 \label{fig:trunSel}
\end{figure}

Like the early breeders modern breeders have to determine a selection threshold $T$ to divide the
total population with the mean $\mu$ into two groups: the individuals culled and the ones allowed to
reproduce with the mean $\mu^{\ast}$. The difference between those two is the selection differential
$S$:

\begin{equation}
 S = \mu^{\ast} - \mu
\label{eqn:S}
\end{equation}
\noindent
In the case of normal distributed data as depicted in figure \ref{fig:trunSel} $S$ can be expressed as:

\begin{equation}
S = \varphi (\frac{T - \mu}{\sigma}) \frac{\sigma}{p}
\end{equation}
\noindent
From which we can obtain the selection intensity $i$, which makes $i$ solely a function of $p$.

\begin{equation}
i = \frac{S}{\sigma} = \frac{\varphi (z_{|1-p|})}{p}
\end{equation}

With recurrent truncation selection over many generations the population mean of the trait
$\mu$ will change (hopefully in the desired direction) if the heritability (in this case
the narrow sense heritability) $h^2$ > 0. It is impossible to breed for traits that do not
contain any genetic components in their architecture \cite{walsh2018}.\\
Next to $i$ the selection intensity and the heritability $h^2$, the accuracy of the selection process
$r_{uA}$ is important for the success of a breeding program. Those three terms can be
applied to estimate the gain of selection $R$ over one generation (equation
\ref{eqn:Breeders}). Due to its importance in the evaluation of breeding schemes it is
known as the breeder's equation \cite{mousseau1987natural}; \cite{falconer1996};
\cite{kingsolver2001strength}.

\begin{equation}
 R = i r_{uA} \sigma_A
\label{eqn:Breeders}
\end{equation}

The accuracy $r_{uA}$ of equation \ref{eqn:Breeders} in cases when only phenotypic
selection is conducted is the narrow-sense heritability and in cases where the selection
process is aided by genomic prediction it is the prediction accuracy \footnote{The
  prediction accuracy in the literature is sometimes used synonymously with predictive
  ability, sometimes the predictive ability is defined as the prediction accuracy divided
  by the narrow or broad sense heritability. In the present study they will be used
  synonymously or termed $\rho_{(y,\hat{y})}$ as the correlation after Pearson between the
  real $y$ and the predicted values $\hat{y}$}. According to the breeder's equation there
are three parameters, which can be influenced through genomic
prediction. \\

\begin{enumerate}[(i)]
\item The prediction accuracy, which is usually smaller than the heritability, varies for
  different prediction equations and an increase in the accuracy will lead to an
  proportional increase in $R$. For this reason since 2001, in quantitative genetics one
  very active field of research was and still is to find new, better algorithms for GS as
  presented in the next chapter (\ref{blup:bayes}). As later evaluated on more than 150
  phenotypes in chapter \ref{gpdis} $h^2$ is almost always larger than $r_{uA}$. Which if
  it was the only variable factor in equation \ref{eqn:Breeders}, would make genomic
  selection inferior to phenotypic selection, which from a certain point of view it
  is. Phenotypic trials are better approximations for phenotypic appearance as genomic
  estimated breeding values (GEBVs). However, as the cost of genotyping has decreased
  dramatically in the last 20 years, phenotyping with field trials remains tedious,
  laborious and vastly expensive. Taking into account that field trials have to be
  repeated in several years and locations to produce robust results, it becomes clear
  that genotyping 10s of thousands of accessions is much cheaper than conducting field
  trials with 1000 of them.
\item The selection intensity can be much stricter if the total population that is
  selected from is larger. In genomic prediction settings they are because breeders can
  select from two pools. First the pool of plants with known phenotypes \underline{and}
  known genotype information and from those where just genomic data is available. When
  selecting from a pool of 1000 with $p=0.05$ with the goal to keep 50 plants in the next
  breeding cycle, the same goal can be reached when genomically selecting from a pool of
  10000 with and intensity of $p=0.005$.
\item The decrease in time per generation is probably the largest advantage of genomic
  selection, when applied to breeding. While in field trials it is only possible to have
  one generation per year, genomic selection does not require the plants to be grown in
  the field. For GS it is only necessary to grow the plants large enough so that DNA can be
  extracted from the tissues and evaluated. After selection only the ones above the
  threshold are grown until they bear seats (or other reproductive organs) and be used for
  the next selection cycle, allowing up to ten generations per year. This development has
  lead to the rise to a new branch of breeding: speed breeding \cite{ghosh2018speed};
  \cite{watson2018speed}. In practical, company-level breeding, genomic prediction has
  largely contributed to an increase by a factor of 2 to the gain in selection in recent
  years (personal communication with breeding company employees).
\end{enumerate}

The last term in equation \ref{eqn:Breeders}, the additive genetic variance $\sigma_A$, is
not directly, yet heavily influenced by the described breeding scheme. Artificial
selection has similar effects on the genetic variance as bottlenecks do in natural
selection: it decreases, thus making it harder to increase $R$ in later selection cycles
\cite{walsh2018}.

\subsubsection{Genomic BLUP and Bayesian methods}\label{blup:bayes}

All methods share a common statistical obstacle, which is commonly referred to as the
$n >> p$ problem, which arises because the number $n$ of markers is usually a multitude
larger than the number of observations $p$. In practical applications it is not uncommon
to have more than 100k markers while the number of phenotypes is no larger than 100. This
does not allow to obtain genomic estimated breeding values (GEBV) by single marker
regression as done by GWAS, which estimates highly inflated SNP-effects
\cite{korte2013advantages}. One possibility is to include effect sizes as random effects
and make prior assumptions about their distribution. The difference in prior distribution
is the main distinction between the many methods of the Bayesian alphabet introduced in
the following chapter \cite{gianola2013}.\\

\noindent
\textbf{Genomic BLUP} \\ In the early years of research on genomic prediction, algorithms
were not solely benchmarked against each other, but had to compete with the previously
popular pedigree-based methods. Quickly in the course of the first decade of this
millennium the superiority of the genomic methods were elucidated in livestock and plant
breeding \cite{habier2007impact}; \cite{vanraden2008efficient};
\cite{vanraden2008reliability}; \cite{harris2009genomic}. While the genomic methods are
superior to non-genomic methods, there is no clear evidence that either of the genomic
methods are superior to each other and there is lack of empirical evidence that the
Bayesian methods generally outperform
GBLUP \cite{moser2009comparison}; \cite{bernardo2010breeding}; \cite{azodi2019}. \\
Like pedigree BLUP for genomic BLUP the co-variance between related individuals is used
for the predictions. In the latter case it is calculated from marker information.
\footnote{In the GWAS terminology the relationship matrix is referred to as $K$ for
  kinship, while in GS circumstances it is called GRM (genomic relationship matrix) or
  abbreviated as $G$. This study will remain consistent with the circumstantial literature
  and therefore purposely inconsistent within itself. In the chapters addressing GWAS it
  will be called $K$ for kinship matrix and in the following chapter elucidating GS it
  will be referred to as $G$.}
\\
The general genomic prediction model (equation \ref{eqn:blup}) is derived from mixed
models \cite{henderson1975best}; \cite{vanraden2008efficient} and implemented as:

\begin{equation}
Y = X \beta + Zu + \varepsilon
 \label{eqn:blup}
\end{equation}

where $Y$ is a $n\;x\;1$ vector of phenotypic observations, $X$ the matrix of the fixed
effects and $\beta$ the vector of the fixed effects. $Z$ is the incidence matrix for the
combined marker effects and $u$ is a $n\; x\; 1$ vector of the additive genetic effect
the vector of the residuals $\varepsilon$.\\
To construct a GBLUP model lets assume a matrix of size $(n\; x\; m)$ with $n$ individuals
and $m$ loci called $M$, containing marker information for three individuals on four loci,
thus being of size $3x4$. The four markers of matrix \ref{arr:M} can take values of $-1$,
$0$ and $1$, translating into minor allele, heterozygous locus and major
allele. \footnote{This example calculation has been adapted from \cite{isik2013}.}

\begin{equation}
 M = 
 \begin{pmatrix}[r]
  -1 & 0 & 1 & -1 \\
  -1 & 0 & 0 & 0 \\
   0 & 1 & 1 & -1 
 \end{pmatrix}
 \label{arr:M}
\end{equation}

The $M$ matrix contains all the information that are necessary for the computation of the K matrix and other viable genetic parameters. The $MM'$ matrix of size $n\; x\; n$ (\ref{arr:MM'}) bears additional parameters.

\begin{equation}
 MM' = 
 \begin{pmatrix}[r]
  3 & 1 & 2 \\
  -1 & 1 & 0 \\
  2 & 0 & 3 
 \end{pmatrix}
 \label{arr:MM'}
\end{equation}

The diagonal shows the number of homozygous loci per individual, while the other elements
of the matrix indicate the number of markers shared by related individuals. This is an
indicator for the distance of the relationship between individuals, as defined by
identity-by-descent \cite{vanraden2008efficient}; \cite{misztal2013methods}. While matrix
\ref{arr:MM'} calculates the metrics per individual, the $M'M$ matrix (\ref{arr:M'M})
accounts for metrics per marker. Likewise the diagonal contains the number of homozygous
individuals per marker.

\begin{equation}
 M'M = 
 \begin{pmatrix}[r]
  3 & -1 & 0 & 0 \\
  -1 & 1 & 1 & 1 \\
  0 & 1 & 2 & 1 \\
  0 & 1 & 1 & 2 
 \end{pmatrix}
 \label{arr:M'M}
\end{equation}

The next step is to obtain a matrix of the allele frequencies at each locus also of size
$n\; x\; m$ like matrix $M$. For the design of matrix $P$ (\ref{arr:P}) let the minor
allele frequencies of the global population $p_1 \dots p_4$ be $\{0.3, 0.2, 0.1, 0.15\}$. The allele frequency of
the $i^{th}$ column of $P$ is expressed according to the $n^{th}$ marker of matrix $M$ as
$P_i = 2(p_i - 0.5)$ resulting in:

\begin{equation}
 P = 
 \begin{pmatrix}[r]
  -0.4 & -0.6 & -0.8 & -0.7 \\
  -0.4 & -0.6 & -0.8 & -0.7 \\
  -0.4 & -0.6 & -0.8 & -0.7
 \end{pmatrix}
 \label{arr:P}
\end{equation}

The allele frequencies, as in this simulated example, should be drawn from the entire
population and not only the subsample used for the calculation
\cite{vanraden2008efficient}. The final step to obtain the Z matrix for the use in equation
\ref{eqn:blup} is to subtract the P matrix from the M matrix $Z= M - P$ resulting in:

\begin{equation}
 Z = 
 \begin{pmatrix}[r]
  1.4 & 0.6 & 1.8 & -0.3 \\
  -0.6 & 0.6 & 0.8 & 0.7 \\
  0.4 & 1.6 & 1.8 & -0.3 \\
 \end{pmatrix}
 \label{arr:Z}
\end{equation}

In $Z$ the mean values of the allele effects are set to 0 and the subtraction of $P$
emphasizes the effect of rare variants \cite{vanraden2008efficient}. There is a large
variety of methods to generate the genomic relationship matrices and here lies the major
difference between different genomic BLUP methods, but K is always of size $n\;x\;n$.

\begin{enumerate}[(i)]
\item The naive approach is to iterate over each individual and count the common markers
  with every other individual. This approach is suited for inbred or doubled-haploid
  populations, less so for outcrossed populations with high degrees of heterozygosity
  because as in the sample implementation it does only account for homozygous loci. This
  method becomes computationally intense when the data sets grow larger as common today
  (personal observation).
\item Probably the most popular method in GS is to obtain $K$ as proposed by
  \cite{vanraden2008efficient} designed after Wright's equations
  \cite{wright1922coefficients} for the covariance in structured populations, as described
  by equation \ref{eqn:vanraden} with $Z$ as in \ref{arr:Z}.

\begin{equation}
 G = \frac{ZZ'}{2 \Sigma p_i (1-p_i)} 
\label{eqn:vanraden}
\end{equation}

In the above example this would result in the following kinship matrix:

\begin{equation}
 G = 
 \begin{pmatrix}[r]
  4.8 & 0.6 & 4.1  \\
  0.6 & 1.6 & 1.7  \\
  4.1 & 1.7 & 5.2  \\
 \end{pmatrix}
 \label{arr:Gship}
\end{equation}


\item The unified additive relationship $G_{UAR}$ according to \cite{yang2010common} and equation \ref{eqn:uar}

\begin{equation}
 G_{UAR} = A_{jk} = \frac{1}{N} \Sigma_i{A_{ijk}} = \left\{
  \!\begin{aligned}
   \frac{1}{N} \Sigma_{i} \frac{(x_{ij} - 2p_i)(x_{ik} - 2p_i)}{2p_i (1-p_i)}, j \ne k \\
   1 + \frac{1}{N} \Sigma_i \frac{x_{ij}^2 (1+2p_i) x_{ij} + 2p_i^2 }{2p_i (1-p_i)}, j = k   
  \end{aligned}
 \right.
 \label{eqn:uar}
\end{equation}

where $p_i$ is the allele frequency at locus $i$ and $x_{ij}$ the genotype for the
$j^{th}$ individual at the $i^th$ locus. Another method also proposed by
\cite{yang2010common} is to adjust $G_{UAR}$ with $\beta$ as in equation \ref{eqn:uaradj}

\begin{equation}
 G_{UARadj} = \left\{
  \!\begin{aligned}
   \beta A_{jk}, \;\; j \ne k \\
   1 + \beta (A_{jk}-1 ), \;\; j = k   
  \end{aligned}
  \right.
 \label{eqn:uaradj}
\end{equation}
with $\beta$ as $\beta = 1 - \frac{c + 1/N}{var(A_{jk})}$ to adjust for the bias in the
estimation of the variance components, where $c$ is the constant of a threshold for minor
allele frequency.


\item Another approach is to weigh markers by the reciprocals of their expected variance
  according to the model \ref{eqn:ZDZ}. This was originally designed to investigate
  population structures in human genomics \cite{leutenegger2003estimation};
  \cite{amin2007genomic}.

\begin{equation}
 \!\begin{aligned}
  G = ZDZ' , with \\
  D_{ii} = \frac{1}{m | 2p_i(1-p_i) | }
 \end{aligned}
 \label{eqn:ZDZ}
\end{equation}

\item Other methods like the gaussian kernel compute kinship between individuals by the euclidean distance
between the respective genotypes \cite{morota2014kernel} as in equation \ref{eqn:gauss}.

\begin{equation}
 \!\begin{aligned}
  K(x_i,x_j) = exp (- \theta d_{ij}^2) \\
  = \prod_{k=1}^m exp (- \theta(x_{ik} - x_{jk})^2)
 \end{aligned}
 \label{eqn:gauss}
\end{equation}

with
$d_{ij} = \sqrt{(x_{i1} - x_{j1})^2 + \dots + (x_{ik} - x_{jk})^2 + \dots + (x_{im} - x_{j,a})^2 }$
and
$ x_{ik}(i,j = 1, \dots , n,k = 1, \dots , m)$ and $x_{ik}$ as the $i^{th}$ individual at SNP $k$. \\
\end{enumerate}

The linear model of equation \ref{eqn:blup} $Y = X \beta + Zu + \varepsilon$, with $\beta$
as the vector of fixed effects and $u$ as the vector of additive genetic effects, can be
solved to obtain genomic estimated breeding values as:

\begin{equation}
 \begin{pmatrix}[ccc]
  X'X & X'Z & 0 \\ 
  Z'X & Z'Z + G^{11} & G^{12} \\ 
  0 & G^{21} & G^{22} \\ 
 \end{pmatrix}
 \begin{pmatrix}[r]
  \hat{b} \\ 
  \hat{y}_1 \\ 
  \hat{y}_2 \\ 
 \end{pmatrix}
 =
 \begin{pmatrix}[r]
  X'y \\ 
  Z'y \\ 
  0 \\ 
 \end{pmatrix}
 \label{eqn:pBLUP}
\end{equation}

with $G^{12}$ as the part of $G^{-1}$ containing individuals \underline{with} phenotypic data and with
$G^{22}$ as the part of $G^{-1}$ containing individuals \underline{without} phenotypic data and just
marker information available.

This can be algebraically solved to compute the GEBV of the unknown phenotypes $\hat{y}_2$  as:

\begin{equation}
\hat{y}_2 = -\left( G^{22}\right)^{-1}G^{21}\hat{y}_1
\label{eqn:gpred}
\end{equation}

GBLUP is fairly easy compared to more complex Bayesian methods and can be quickly implemented in any
programming language capable of solving liner equations like R or Python \cite{CRAN};
\cite{van1995python}. Computationally, as the number of phenotypes in the study increases in numbers,
the time demand grows exponentially because the kinship matrix quadruples in size and
it becomes more complicated to compute the inverse of $G$ (personal observations). \\

\noindent
\textbf{Bayesian methods} \\ 

Next to the universal GBLUP a set of related algorithms became popular for solving the mixed models
involved in genomic selection, known as the Bayesian alphabet \cite{gianola2009};
\cite{gianola2013}. They are all based on Bayes' fundamental theorem (equation \ref{eqn:bayes}).

\begin{equation}
P(\theta | y) = \frac{P(\theta )P(y | \theta)}{P(y)} 
\label{eqn:bayes}
\end{equation}

with $P(\theta )$ as the prior distribution, $P(y|\theta )$ as the likelihood and $P(y)$
as the marginal density of $y$. The prior distribution in GS assume that $y$ was drawn
from a certain distribution. Infinitesimal models assume that the genetic effects follow a
normal distribution \cite{legarra2018}, while the Bayesian frameworks, however, will
assume non-normal distributed marker effects. This can be explained by a two-step
hierarchical model. Stage one assumes that every marker has \textit{a priori} a
different variance \cite{legarra2018}.

\begin{equation}
p(a_i|\sigma_{ai}^2) = N (0,\sigma^1_{ai})
 \label{eqn:stageonbayes}
\end{equation}

The second stage assumes prior distributions for the variances.

\begin{equation}
p(a_i| variable ) = P(\dots )
 \label{eqn:stagetwobayes}
\end{equation}

with $variable$ standing for the large variety of prior distributions. In total there are
more than 20 different Bayesian models known to the author and probably some more unknown
ones. Their main difference ``simply'' lies in the \textit{a priori} assumptions of prior
distributions. This change can make some methods mathematically much more complicated then
others. As shown in later chapters none of the methods is completely superior over others
in terms of
prediction accuracy. \\
Approximation to the solution of the linear equations is usually performed by Gibb's
sampling using Markov Chain Monte Carlo (MCMC) simulations \cite{dlc2009}; \cite{BGLR}.
Table \ref{tab:bayesABC} summarizes commonly applied Bayesian methods for genomic
prediction indicating their key differences.

\begin{table}[H]
\caption{Overview of properties of a variety of commonly applied Bayesian methods for genomic prediction. Table altered after \cite{karkkainen2012back}}
\label{tab:bayesABC}
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{lcccccc}
 \toprule
 Name        & Reference                  & Prior   & Indicator & Hierarchy & Hyperprior & Estimation \\
 \midrule
 BayesA      & \cite{hayes2001}           & Student & No        & Yes       & No         & MCMC       \\
 BayesB      & \cite{hayes2001}           & Student & Yes       & Yes       & No         & MCMC       \\
 BayesC      & \cite{verbyla2009accuracy} & Student & Yes       & Yes       & No         & MCMC       \\
 BL          & \cite{xu2010expectation}   & Laplace & No        & Yes       & No         & EM         \\
 BayesD$\pi$ & \cite{habier2011}          & Student & Yes       & Yes       & Yes        & MCMC       \\
                            \bottomrule                          
                          \end{tabular}}
\caption*{The name is given by the author. The prior column tells which shrinkage prior is used. }
\end{table}


\subsection{Genomic selection using artificial neural networks } \label{ch:gs-ann}

As mentioned in \ref{intro:gs} genomic selection (GS) has been successfully applied in
animal \cite{hayes2010genome}; \cite{gianola2015one} and plant breeding \cite{crossa2010};
\cite{heffner2010plant}; \cite{desta2014genomic}; \cite{crossa2017} as well as in medical
applications since it was first reported by \cite{hayes2001}. Since then the repertoire of
methods for predicting phenotypic values has increased rapidly e.g. \cite{dlc2009};
\cite{habier2011}; \cite{gianola2013}; \cite{crossa2017}. Genomic prediction has
repeatedly been proven to outperform pedigree-based methods \cite{crossa2010};
\cite{albrecht2011} and is nowadays used in many plant and animal breeding schemes. It has
also been shown that using whole-genome information is superior to using only
feature-selected markers with known QTLs for a given trait \cite{bernardo2007};
\cite{heffner2011} in most cases. A more recent study \cite{azodi2019} compared 11
different genomic prediction algorithms with a variety of data sets and found
contradicting results, indicating that feature selection can be useful for some cases
when whole genome regression is performed by neural nets. \\
While every new method is a valuable addition to the toolbox of genomic selection, some
fundamental problems remain unsolved and are the same for every algorithm, of which the
$n>>p$ problematic stands out. Usually in genomic selection settings the size of the
training population (TRN) with $p$ phenotypes is substantially smaller than the number of
markers $n$ \cite{fan2014challenges}, making the number of trainable features immensely
large. Furthermore, every marker is treated as an independent observation neglecting
collinearity and linkage disequilibrium (LD) between them. More difficulties arise through
non-additive, epistatic and dominance marker effects. The main issue with epistasis in
quantitative genetics is the almost infinite amount of different marker combinations,
which cannot be represented within the size of TRN in the thousands. The same problems
arises in GWA studies \cite{korte2013advantages}. With already large $n$ the number of
possible additive SNP-SNP interactions potentiates to $n^{(n-1)}$. Methods that attempt to
overcome those issues are EG-BLUP, which use an enhanced epistatic kinship matrix and
reproducing kernel Hilbert space regression (RKHS) \cite{jiang2015}; \cite{martini2017genomic}. \\
In the past 10 years, due to increasing availability of high performance computational
hardware with decreasing costs and parallel development of free easy-to-use software, most
prominent being googles library TensorFlow \cite{TF2016} and Keras \cite{keras2015},
machine learning (ML) has experienced a renaissance. ML is a set of methods and algorithms
used widely for regression and classification problems. Popular among those are
e.g. support vector machines, multi-layer perceptrons (MLP) and convolutional neural
networks. ML has been widely applied in many biological fields
\cite{mamoshina2016applications}; \cite{rampasek2016tensorflow}; \cite{angermueller2016};
\cite{min2017deep}; \cite{lan2018survey}; \cite{webb2018deep}. \\
A variety of studies assessed the usability of ML in genomic prediction
\cite{ogutu2011comparison}; \cite{gonza2012}; \cite{gonza2016}; \cite{qiu2016application};
\cite{ma2017deepgs}; \cite{gonzalez2018applications}; \cite{grinberg2018evaluation};
\cite{li2018genomic} \cite{montesinos2019benchmarking}; \cite{cuevas2019deep};
\cite{montesinos2019new}. Through all those studies the common denominator is that there
is no such thing as a gold standard for genomic prediction. No single algorithm was able
to outperform all the others tested in a single of those studies, let alone in all. While
the general aptitude of ML for genomic selection has been repeatedly proven, there is no
evidence that neural networks can generally outperform
mixed-model approaches as GBLUP \cite{hayes2001}. \\
In other fields like image classification neural networks have up to 100s of hidden layers
\cite{he2016deep}. The commonly used fully-connected networks in genomic prediction tend
to have one to three hidden layers. With one layer networks often being the most
successful among those. Contradicting to the idea behind machine learning in genomic
selection one hidden layer networks will be inapt to capture interactions between loci and
thus only account for additive effects. As shown in \cite{azodi2019} convolutional
networks perform worse than fully-connected networks in genomic selection, which again is
contradicting to other fields where convolutional layers are applied successfully, e.g.
natural language processing \cite{dos2014deep} or medical image analysis
\cite{litjens2017survey}. Instead of using convolutional layers and fully-connected layers
only, as shown in Pook et al 2019, we also propose to use locally-connected layer in
combination with fully-connected layers. While CL and LCL are closely related they have a
significant difference. In CL weights are shared between neurons and in LCLs each neuron
has its own weight. This leads to a reduced number of parameters to be trained in the
following FCLs and should therefore theoretically lead to a decrease in overfitting. To
evaluate the usefulness of machine learning in GS the data sets generated in the scope of
the 1001 genome project of \textit{A. thaliana} \cite{1001genome} and the MAZE project
were used.

\section{Proof of concept for ANN-based genomic selection} \label{POC}

Having established the quantitative architecture of traits in section \ref{quan} and the
basics of machine learning and neural nets in section \ref{introml}, that knowledge can be
used to provide a proof of concept that neural networks are a candidate for GP. Table
\ref{tab:simmarker} provides all the possible genotypes $G_1 \dots G_4$ that can be
derived by two bi-allelic markers $M_1,M_2$ on a fictional haploid organism. In this
simulation the effect sizes for each marker $\beta_1$ and $\beta_2$ are constant with a
value of 1.

\begin{table}[H]
  \caption{Simple simulated phenotypes and genotypes for genomic prediction with genotypes
    $G_1 \dots G_4$, Markers $M_1$ and $M_2$ and phenotypes based on additive effects or
    $and$, $or$, $xor$ logic gates.}
\label{tab:simmarker}
\centering
\begin{tabular}{ l c c | c c c c c c }
  \toprule
  & $M_1$ & $M_2$ & $Y_{ADD}$ & $Y_{AND}$ & $Y_{OR}$ & $Y_{XOR}$\\
  \midrule
  $G_1$ & 0 & 0 & 0 & 0 & 0 & 0 \\
  $G_2$ & 0 & 1 & 1 & 0 & 1 & 1 \\
  $G_3$ & 1 & 0 & 1 & 0 & 1 & 1 \\
  $G_4$ & 1 & 1 & 2 & 1 & 1 & 0 \\
  \bottomrule
\end{tabular}
\end{table}

The four phenotypes $Y_{ADD}$, $Y_{AND}$, $Y_{OR}$ and $Y_{XOR}$ , which were derived from
their respective marker effects, were used for GP. $Y_{ADD}$ is a phenotype with purely
additive effects. So in the nomenclature introduced in chapter \ref{quan}
$\sigma_A = \sigma_G$ and $\sigma_{I} = 0$. Since the hypothetical organism is haploid
there are no dominance effects to be accounted for $\sigma_D = 0$ and since all the
genetic effects are caused by additive effects and there are also no environmental effects
$\sigma_E$.  The narrow sense heritability $h^2$ - equation \ref{eqn:h2a} - and the broad
sense heritability $H^2$ - equation \ref{eqn:h2G} - are equally 1. The other three
phenotypes are based on epistatic effects $\sigma_I$, generated by passing the markers
$M_1$ and $M_2$ through their respective logic gates. This theoretically results in
$h^2 = 0$ and $H^2 = 1$ because there should be no additive effects. For $y_{AND}$
,however, $h \approx 0.5$ because there is a correlation between $Y_{ADD}$ and
$Y_{AND}$. In practical applications this allows methods like GBLUP, designed to account
for additive genetic effects, to capture some of the epistatic effects of $\sigma_I$
\cite{vieira2017assessing}.

According to chapter \ref{introml} a single perceptron fails to solve $xor$ gates. While a
network with multiple nodes and layers should be able to overcome that deficit. A
relatively simple neural network with two fully-connected hidden layers with 10 and 5
nodes was trained for the prediction of the phenotypes. To keep the simulation as simple
possible, no regularization parameters like dropout etc. were included. The activation
function was ReLU (\ref{eqn:relu}) with an Adam optimizer. The results of the prediction
are shown in table \ref{tab:simgpres}.

\begin{table}[H]
\caption{Results of genomic prediction from phenotypes and genotypes in table \ref{tab:simmarker}}
\label{tab:simgpres}
\centering
\begin{tabular}{ l c c | c c c c c c }
 \toprule
 & $M_1$ & $M_2$ & $\hat{Y}_{ADD}$ & $\hat{Y}_{AND}$ & $\hat{Y}_{OR}$ & $\hat{Y}_{XOR}$\\
 \midrule
 \hline 
 $G_1$ & 0 & 0 & 0.01 & 0.00 & 0.00 & 0.01 \\
 $G_2$ & 0 & 1 & 0.99 & 0.01 & 0.99 & 0.98 \\
 $G_3$ & 1 & 0 & 0.99 & 0.00 & 0.99 & 1.01 \\
 $G_4$ & 1 & 1 & 1.99 & 0.98 & 1.01 & 0.02 \\
 \bottomrule
\end{tabular}
\end{table}

Not surprisingly, the simple network is able to solve all four problems and predict the
phenotypes accurately. The task was rather easy because the training data set and the
testing data set were the same, but it served the purpose of showing that neural networks
are generally apt to solve different marker interactions. \\
\textit{In natura} those interactions and the overall genetic architecture are much more
complex. Effect sizes are not constant and epistasis may be caused by
interactions with more than just two markers. With an increasing number of markers the
number of possible two way interactions increases even more to $2^{n-1}$. Smaller
interaction effects could be obscured under larger additive effects. Gene-environment
interactions might have a significant influence resulting in a model that does not
converge.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
