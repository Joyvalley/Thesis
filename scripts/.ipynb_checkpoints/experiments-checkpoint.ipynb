{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic prediction with neural networks\n",
    "Some preliminary experiments to find theoretical limitations and a suitable network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1024 16:01:29.564326 139736234739520 deprecation.py:506] From /home/joyvalley/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# build simple network for two marker system (architecture 4,2)\n",
    "weights = {}\n",
    "biases = {}\n",
    "n_markers = 2\n",
    "archit = [8, 4]\n",
    "n_layers = len(archit)\n",
    "n_outputs = 1\n",
    "initial_learning_rate = 0.01\n",
    "beta = 0.01\n",
    "\n",
    "weights['h1'] = tf.Variable(tf.random_normal([n_markers, archit[0]]))\n",
    "biases['b1'] = tf.Variable(tf.random_normal([archit[0]]))\n",
    "for l in range(1,n_layers):\n",
    "    w_name = 'h' + str(l+1)\n",
    "    b_name = 'b' + str(l+1)\n",
    "    weights[w_name] = tf.Variable(tf.random_normal([archit[l-1], archit[l]]))\n",
    "    biases[b_name] = tf.Variable(tf.random_normal([archit[l]]))\n",
    "weights['out'] = tf.Variable(tf.random_normal([archit[-1], n_outputs]))\n",
    "biases['out'] = tf.Variable(tf.random_normal([n_outputs]))\n",
    "\n",
    "nn_x = tf.placeholder(tf.float32, [None, n_markers])\n",
    "nn_y = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "\n",
    "layer = nn_x\n",
    "for l in range(1,n_layers+1):\n",
    "    weight_name = 'h' + str(l)\n",
    "    bias_name = 'b' + str(l)\n",
    "    layer = tf.add(tf.matmul(layer, weights[weight_name]), biases[bias_name])\n",
    "    ### CHANGE activation function here (sigmoid, relu, elu, tanh, crelu, softsign)\n",
    "    layer = tf.nn.relu(layer) \n",
    "pred = tf.matmul(layer, weights['out']) + biases['out']\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(pred - nn_y))   # Mean squared error\n",
    "regularizer = tf.nn.l2_loss(weights['h1']) + tf.nn.l2_loss(weights['h2'])\n",
    "loss = tf.reduce_mean(loss + beta * regularizer)\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, 1000, 0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genos = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "phenos_xor = np.array([[0],[1],[1],[0]])\n",
    "phenos_xnor = np.array([[1],[0],[0],[1]])\n",
    "phenos_or = np.array([[0],[1],[1],[1]])\n",
    "phenos_nor = np.array([[1],[0],[0],[0]])\n",
    "phenos_and = np.array([[0],[0],[0],[1]])\n",
    "phenos_add = np.array([[0],[1],[1],[2]])\n",
    "phenos_xnor_plus_const = np.array([[3],[2],[2],[3]])\n",
    "phenos = phenos_xnor_plus_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost= 0.024161348\n",
      "[[2.9841018]\n",
      " [2.0279999]\n",
      " [2.01961  ]\n",
      " [2.9719043]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(optimizer, feed_dict = {nn_x:genos, nn_y:phenos})\n",
    "c = sess.run(loss,feed_dict = {nn_x:genos, nn_y:phenos})\n",
    "\n",
    "print(\"Cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "# Predict everything\n",
    "predicted_phenos = sess.run(pred, feed_dict={nn_x: genos})\n",
    "print(predicted_phenos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost= 0.024168370\n",
      "[[2.9840677]\n",
      " [2.0278132]\n",
      " [2.019473 ]\n",
      " [2.9717152]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(optimizer, feed_dict = {nn_x:genos, nn_y:phenos})\n",
    "    c = sess.run(loss,feed_dict = {nn_x:genos, nn_y:phenos})\n",
    "\n",
    "print(\"Cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "# Predict everything\n",
    "predicted_phenos = sess.run(pred, feed_dict={nn_x: genos})\n",
    "print(predicted_phenos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': array([[ 6.7333043e-01, -1.1514398e-22, -1.1214536e-20, -1.5130287e-01,\n",
       "         -8.6391795e-01,  7.1052620e-23,  3.2868320e-01, -1.7554271e-10],\n",
       "        [ 1.9128023e-01, -5.9814138e-05,  7.1015435e-21,  3.0976614e-01,\n",
       "         -8.6372197e-01, -2.3437361e-24, -5.9490955e-01,  8.5702115e-21]],\n",
       "       dtype=float32),\n",
       " 'h2': array([[ 3.0668303e-01,  9.2997300e-03, -1.6778873e-25,  7.0171458e-01],\n",
       "        [ 4.3126897e-04,  1.4740734e-18, -1.4325245e-21, -2.5458369e-01],\n",
       "        [ 5.7633719e-25, -5.1869715e-25,  2.1417069e-21, -4.0303690e-25],\n",
       "        [-1.5135466e-01, -3.4977896e-10,  1.4189316e-24, -1.4601047e-01],\n",
       "        [ 6.2089431e-01,  6.9221771e-24, -2.1638889e-24,  7.8437334e-01],\n",
       "        [-2.0931813e-25, -8.7192600e-09, -9.2813982e-25,  5.0352644e-24],\n",
       "        [-2.7397519e-01, -5.6292014e-22, -4.2355621e-23, -6.2226111e-01],\n",
       "        [ 4.1702507e-23,  3.9547594e-25, -1.1935764e-08, -2.0372886e-19]],\n",
       "       dtype=float32),\n",
       " 'out': array([[ 0.8012502 ],\n",
       "        [ 0.3126491 ],\n",
       "        [-0.91907054],\n",
       "        [ 1.5368633 ]], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
